{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlH0lCOttCs5"
      },
      "source": [
        "<img src=\"https://fsdl.me/logo-720-dark-horizontal\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUPRHaeetRnT"
      },
      "source": [
        "# Lab 05: Troubleshooting & Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bry3Hr-PcgDs"
      },
      "source": [
        "### What You Will Learn\n",
        "\n",
        "- Practices and tools for testing and linting Python code in general: `black`, `flake8`, `precommit`, `pytests` and `doctests`\n",
        "- How to implement tests for ML training systems in particular\n",
        "- What a PyTorch training step looks like under the hood and how to troubleshoot performance bottlenecks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs0LXXlCU6Ix"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkQiK7lkgeXm"
      },
      "source": [
        "If you're running this notebook on Google Colab,\n",
        "the cell below will run full environment setup.\n",
        "\n",
        "It should take about three minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sVx7C7H0PIZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b7dae6-f2e6-4271-f830-f0f0f356e5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=.:/env/python\n",
            ".:/env/python\n",
            "/content/fsdl-text-recognizer-2022-labs/lab05\n",
            "\u001b[0m\u001b[01;34mnotebooks\u001b[0m/  \u001b[01;34mtasks\u001b[0m/  \u001b[01;34mtext_recognizer\u001b[0m/  \u001b[01;34mtraining\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "lab_idx = 5\n",
        "\n",
        "if \"bootstrap\" not in locals() or bootstrap.run:\n",
        "    # path management for Python\n",
        "    pythonpath, = !echo $PYTHONPATH\n",
        "    if \".\" not in pythonpath.split(\":\"):\n",
        "        pythonpath = \".:\" + pythonpath\n",
        "        %env PYTHONPATH={pythonpath}\n",
        "        !echo $PYTHONPATH\n",
        "\n",
        "    # get both Colab and local notebooks into the same state\n",
        "    #!wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n",
        "    !wget --quiet https://gist.githubusercontent.com/mchen50/0b202810bdc771b010f018561b48e3ef/raw/17e9ee7cca20fefdd1c07f803818d843c1411bc1/gistfile1.txt -O bootstrap.py\n",
        "    import bootstrap\n",
        "\n",
        "    # change into the lab directory\n",
        "    bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n",
        "\n",
        "    # allow \"hot-reloading\" of modules\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "    # needed for inline plots in some contexts\n",
        "    %matplotlib inline\n",
        "\n",
        "    bootstrap.run = False  # change to True re-run setup\n",
        "\n",
        "!pwd\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sThWeTtV6fL_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a4d74e0c-e15c-4d2e-93b6-54d2e27b4a2d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.output_result { max-width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, HTML, IFrame\n",
        "\n",
        "full_width = True\n",
        "frame_height = 720  # adjust for your screen\n",
        "\n",
        "if full_width:  # if we want the notebook to take up the whole width\n",
        "    # add styling to the notebook's HTML directly\n",
        "    display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
        "    display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYQFDfdBIgUD"
      },
      "source": [
        "### Follow along with a video walkthrough on YouTube:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyAfPM9SIgUE"
      },
      "outputs": [],
      "source": [
        "IFrame(src=\"https://fsdl.me/2022-lab-05-video-embed\", width=\"100%\", height=frame_height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFP8lU4nSg1P"
      },
      "source": [
        "# Linting Python and Shell Scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXbdYfFlPhZ-"
      },
      "source": [
        "### Automatically linting with `pre-commit`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysqqb2GjvLrz"
      },
      "source": [
        "We want keep our code clean and uniform across developers\n",
        "and time.\n",
        "\n",
        "Applying the cleanliness checks and style rules should be\n",
        "as painless and automatic as possible.\n",
        "\n",
        "For this purpose, we recommend bundling linting tools together\n",
        "and enforcing them on all commits with\n",
        "[`pre-commit`](https://pre-commit.com/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvqtZChKvLr0"
      },
      "source": [
        "In addition to running on every commit,\n",
        "`pre-commit` separates the model development environment from the environments\n",
        "needed for the linting tools, preventing conflicts\n",
        "and simplifying maintenance and onboarding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0XuIuKOXhJl"
      },
      "source": [
        "This cell runs `pre-commit`.\n",
        "\n",
        "The first time it is run on a machine, it will install the environments for all tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hltYGbpNvLr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e89f6a5-4d5a-416b-b00f-9c7952255006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]\u001b[m Initializing environment for https://github.com/pre-commit/pre-commit-hooks.\n",
            "[INFO]\u001b[m Initializing environment for https://github.com/psf/black.\n",
            "[INFO]\u001b[m Initializing environment for https://github.com/PyCQA/flake8.\n",
            "[INFO]\u001b[m Initializing environment for https://github.com/PyCQA/flake8:flake8-bandit,flake8-bugbear,flake8-docstrings,flake8-import-order,darglint,mypy,pycodestyle,pydocstyle.\n",
            "[INFO]\u001b[m Initializing environment for https://github.com/shellcheck-py/shellcheck-py.\n",
            "[INFO]\u001b[m Installing environment for https://github.com/pre-commit/pre-commit-hooks.\n",
            "[INFO]\u001b[m Once installed this environment will be reused.\n",
            "[INFO]\u001b[m This may take a few minutes...\n",
            "[INFO]\u001b[m Installing environment for https://github.com/psf/black.\n",
            "[INFO]\u001b[m Once installed this environment will be reused.\n",
            "[INFO]\u001b[m This may take a few minutes...\n",
            "[INFO]\u001b[m Installing environment for https://github.com/PyCQA/flake8.\n",
            "[INFO]\u001b[m Once installed this environment will be reused.\n",
            "[INFO]\u001b[m This may take a few minutes...\n",
            "[INFO]\u001b[m Installing environment for https://github.com/shellcheck-py/shellcheck-py.\n",
            "[INFO]\u001b[m Once installed this environment will be reused.\n",
            "[INFO]\u001b[m This may take a few minutes...\n",
            "trim trailing whitespace.................................................\u001b[42mPassed\u001b[m\n",
            "check toml...............................................................\u001b[42mPassed\u001b[m\n",
            "check yaml...............................................................\u001b[42mPassed\u001b[m\n",
            "check json...............................................................\u001b[42mPassed\u001b[m\n",
            "check for merge conflicts................................................\u001b[42mPassed\u001b[m\n",
            "check for added large files..............................................\u001b[42mPassed\u001b[m\n",
            "debug statements (python)................................................\u001b[42mPassed\u001b[m\n",
            "detect private key.......................................................\u001b[42mPassed\u001b[m\n",
            "black....................................................................\u001b[42mPassed\u001b[m\n",
            "flake8...................................................................\u001b[42mPassed\u001b[m\n",
            "shellcheck...............................................................\u001b[42mPassed\u001b[m\n"
          ]
        }
      ],
      "source": [
        "!pre-commit run --all-files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLw08gIkvLr1"
      },
      "source": [
        "The output lists all the checks that are run and whether they are passed.\n",
        "\n",
        "Notice there are a number of simple version-control hygiene practices included\n",
        "that aren't even specific to Python, much less to machine learning.\n",
        "\n",
        "For example, several of the checks prevent accidental commits with private keys, large files,\n",
        "leftover debugger statements, or merge conflict annotations in them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHEEjb9kvLr1"
      },
      "source": [
        "These linting actions are configured via\n",
        "([what else?](https://twitter.com/charles_irl/status/1446235836794564615?s=20&t=OOK-9NbgbJAoBrL8MkUmuA))\n",
        "a YAML file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgXa8BzrvLr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c4d3e6-7e6e-49ed-86f8-d11452d4f305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repos:\n",
            "  # a set of useful Python-based pre-commit hooks\n",
            "  - repo: https://github.com/pre-commit/pre-commit-hooks\n",
            "    rev: v4.1.0\n",
            "    hooks:\n",
            "      # list of definitions and supported hooks: https://pre-commit.com/hooks.html\n",
            "      - id: trailing-whitespace      # removes any whitespace at the ends of lines\n",
            "      - id: check-toml               # check toml syntax by loading all toml files\n",
            "      - id: check-yaml               # check yaml syntax by loading all yaml files\n",
            "      - id: check-json               # check-json syntax by loading all json files\n",
            "      - id: check-merge-conflict     # check for files with merge conflict strings\n",
            "        args: ['--assume-in-merge']  #  and run this check even when not explicitly in a merge\n",
            "      - id: check-added-large-files  # check that no \"large\" files have been added\n",
            "        args: ['--maxkb=10240']      #  where large means 10MB+, as in Hugging Face's git server\n",
            "      - id: debug-statements         # check for python debug statements (import pdb, breakpoint, etc.)\n",
            "      - id: detect-private-key       # checks for private keys (BEGIN X PRIVATE KEY, etc.)\n",
            "\n",
            "  # black python autoformatting\n",
            "  - repo: https://github.com/psf/black\n",
            "    rev: 22.3.0\n",
            "    hooks:\n",
            "      - id: black\n",
            "    # additional configuration of black in pyproject.toml\n",
            "\n",
            "  # flake8 python linter with all the fixins\n",
            "  - repo: https://github.com/PyCQA/flake8\n",
            "    rev: 3.9.2\n",
            "    hooks:\n",
            "      - id: flake8\n",
            "        exclude: (lab01|lab02|lab03|lab04|lab06|lab07|lab08)\n",
            "        additional_dependencies: [\n",
            "          flake8-bandit, flake8-bugbear, flake8-docstrings,\n",
            "          flake8-import-order, darglint, mypy, pycodestyle, pydocstyle]\n",
            "        args: [\"--config\", \".flake8\"]\n",
            "    # additional configuration of flake8 and extensions in .flake8\n",
            "\n",
            "  # shellcheck-py for linting shell files\n",
            "  - repo: https://github.com/shellcheck-py/shellcheck-py\n",
            "    rev: v0.8.0.4\n",
            "    hooks:\n",
            "      - id: shellcheck\n"
          ]
        }
      ],
      "source": [
        "!cat .pre-commit-config.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HYc_WbTvLr2"
      },
      "source": [
        "Most of the general cleanliness checks are from hooks built by `pre-commit`.\n",
        "\n",
        "See the comments and links in the `.pre-commit-config.yaml` for more:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9rTgRqzvLr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae9cef2-f8b9-4c68-b14d-b2eb831d9b2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repos:\n",
            "  # a set of useful Python-based pre-commit hooks\n",
            "  - repo: https://github.com/pre-commit/pre-commit-hooks\n",
            "    rev: v4.1.0\n",
            "    hooks:\n",
            "      # list of definitions and supported hooks: https://pre-commit.com/hooks.html\n",
            "      - id: trailing-whitespace      # removes any whitespace at the ends of lines\n",
            "      - id: check-toml               # check toml syntax by loading all toml files\n",
            "      - id: check-yaml               # check yaml syntax by loading all yaml files\n",
            "      - id: check-json               # check-json syntax by loading all json files\n",
            "      - id: check-merge-conflict     # check for files with merge conflict strings\n",
            "        args: ['--assume-in-merge']  #  and run this check even when not explicitly in a merge\n",
            "      - id: check-added-large-files  # check that no \"large\" files have been added\n",
            "        args: ['--maxkb=10240']      #  where large means 10MB+, as in Hugging Face's git server\n",
            "      - id: debug-statements         # check for python debug statements (import pdb, breakpoint, etc.)\n",
            "      - id: detect-private-key       # checks for private keys (BEGIN X PRIVATE KEY, etc.)\n"
          ]
        }
      ],
      "source": [
        "!cat .pre-commit-config.yaml | grep repos -A 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ptkO7aPvLr2"
      },
      "source": [
        "Let's take a look at the section of the file\n",
        "that applies most of our Python style enforcement with\n",
        "[`flake8`](https://flake8.pycqa.org/en/latest/):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALsRKfcevLr3",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3010ab11-16f8-433b-a362-f0ec5969e40b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  # flake8 python linter with all the fixins\n",
            "  - repo: https://github.com/PyCQA/flake8\n",
            "    rev: 3.9.2\n",
            "    hooks:\n",
            "      - id: flake8\n",
            "        exclude: (lab01|lab02|lab03|lab04|lab06|lab07|lab08)\n",
            "        additional_dependencies: [\n",
            "          flake8-bandit, flake8-bugbear, flake8-docstrings,\n",
            "          flake8-import-order, darglint, mypy, pycodestyle, pydocstyle]\n",
            "        args: [\"--config\", \".flake8\"]\n",
            "    # additional configuration of flake8 and extensions in .flake8\n"
          ]
        }
      ],
      "source": [
        "!cat .pre-commit-config.yaml | grep \"flake8 python\" -A 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_Q0BwQUXbg6"
      },
      "source": [
        "The majority of the style checking behavior we want comes from the\n",
        "`additional_dependencies`, which are\n",
        "[plugins](https://flake8.pycqa.org/en/latest/glossary.html#term-plugin)\n",
        "that extend `flake8`'s list of lints.\n",
        "\n",
        "Notice that we have a `--config` file passed in to the `args` for the `flake8` command.\n",
        "\n",
        "We keep the configuration information for `flake8`\n",
        "separate from that for `pre-commit`\n",
        "in case we want to use additional tools with `flake8`,\n",
        "e.g. if some developers want to integrate it directly into their editor,\n",
        "and so that if we change away from `.pre-commit`\n",
        "but keep `flake8` we don't have to\n",
        "recreate our configuration in a different tool.\n",
        "\n",
        "As much as possible, codebases should strive for single sources of truth\n",
        "and link back to those sources of truth with documentation or comments,\n",
        "as in the last line above.\n",
        "\n",
        "Let's take a look at the contents of `flake8`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doC_4WQwvLr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b2ac3a-b39e-46c1-ad01-27dfc72ed62c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flake8]\n",
            "select = ANN,B,B9,BLK,C,D,E,F,I,S,W\n",
            "  # only check selected error codes\n",
            "max-complexity = 12\n",
            "  # C9 - flake8 McCabe Complexity checker -- threshold\n",
            "max-line-length = 120\n",
            "  # E501 - flake8 -- line length too long, actually handled by black\n",
            "extend-ignore =\n",
            "  # E W - flake8 PEP style check\n",
            "    E203,E402,E501,W503,  # whitespace, import, line length, binary operator line breaks\n",
            "  # S - flake8-bandit safety check\n",
            "    S101,S113,S311,S105,  # assert removed in bytecode, no request timeout, pRNG not secure, hardcoded password\n",
            "  # ANN - flake8-annotations type annotation check\n",
            "    ANN,ANN002,ANN003,ANN101,ANN102,ANN202,  # ignore all for now, but always ignore some\n",
            "  # D1 - flake8-docstrings docstring style check\n",
            "    D100,D102,D103,D104,D105,  # missing docstrings\n",
            "  # D2 D4 - flake8-docstrings docstring style check\n",
            "    D200,D205,D400,D401,  # whitespace issues and first line content\n",
            "  # DAR - flake8-darglint docstring correctness check\n",
            "    DAR103,  # mismatched or missing type in docstring\n",
            "application-import-names = app_gradio,text_recognizer,tests,training\n",
            "  # flake8-import-order: which names are first party?\n",
            "import-order-style = google\n",
            "  # flake8-import-order: which import order style guide do we use?\n",
            "docstring-convention = numpy\n",
            "  # flake8-docstrings: which docstring style guide do we use?\n",
            "strictness = short\n",
            "  # darglint: how \"strict\" are we with docstring completeness?\n",
            "docstring-style = numpy\n",
            "  # darglint: which docstring style guide do we use?\n",
            "suppress-none-returning = true\n",
            "  # flake8-annotations: do we allow un-annotated Nones in returns?\n",
            "mypy-init-return = true\n",
            "  # flake8-annotations: do we allow init to have no return annotation?\n",
            "per-file-ignores =\n",
            "  # list of case-by-case ignores, see files for details\n",
            "  */__init__.py:F401,I\n",
            "  */data/*.py:DAR\n",
            "  data/*.py:F,I\n",
            "  *text_recognizer/util.py:DAR101,F401\n",
            "  *training/run_experiment.py:I202\n",
            "  *app_gradio/app.py:I202\n"
          ]
        }
      ],
      "source": [
        "!cat .flake8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nq6HnyU0M47"
      },
      "source": [
        "There's a lot here! We'll focus on the most important bits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4PiB8CPvLr3"
      },
      "source": [
        "Linting tools in Python generally work by emitting error codes\n",
        "with one or more letters followed by three numbers.\n",
        "The `select` argument picks which error codes we want to check for.\n",
        "Error codes are matched by prefix,\n",
        "so for example `B` matches `BTS101` and\n",
        "`G1` matches `G102` and `G199` but not `ARG404`.\n",
        "\n",
        "Certain codes are `ignore`d in the default `flake8` style,\n",
        "which is done via the `ignore` argument,\n",
        "and we can `extend` the list of `ignore`d codes with `extend-ignore`.\n",
        "For example, we rely on `black` to do our formatting,\n",
        "so we ignore some of `flake8`'s formatting codes.\n",
        "\n",
        "Together, these settings define our project's particular style.\n",
        "\n",
        "But not every file fits this style perfectly.\n",
        "Most of the conventions in `black` and `flake8` come from the style-defining\n",
        "[Python Enhancement Proposal 8](https://peps.python.org/pep-0008/),\n",
        "which exhorts you to \"know when to be inconsistent\".\n",
        "\n",
        "To allow ourselves to be inconsistent when we know we should be,\n",
        "`flake8` includes `per-file-ignores`,\n",
        "which let us ignore specific warnings in specific files.\n",
        "This is one of the \"escape valves\"\n",
        "that makes style enforcement tolerable.\n",
        "We can also `exclude` files in the `pre-commit` config itself.\n",
        "\n",
        "For details on selecting and ignoring,\n",
        "see the [`flake8` docs](https://flake8.pycqa.org/en/latest/user/violations.html)\n",
        "\n",
        "For definitions of the error codes from `flake8` itself,\n",
        "see the [list in the docs](https://flake8.pycqa.org/en/latest/user/error-codes.html).\n",
        "Individual extensions list their added error codes in their documentation,\n",
        "e.g. `darglint` does so\n",
        "[here](https://github.com/terrencepreilly/darglint#error-codes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL0TpyPsvLr4"
      },
      "source": [
        "The remainder are configurations for the other `flake8` plugins that we use to define and enforce the rest of our style.\n",
        "\n",
        "You can read more about each in their documentation:\n",
        "- [`flake8-import-order`](https://github.com/PyCQA/flake8-import-order) for checking imports\n",
        "- [`flake8-docstrings`](https://github.com/pycqa/flake8-docstrings) for docstring style\n",
        "- [`darglint`](https://github.com/terrencepreilly/darglint) for docstring completeness\n",
        "- [`flake8-annotations`](https://github.com/sco1/flake8-annotations) for type annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFsZC0a7vLr4"
      },
      "source": [
        "### Linting via a script and using `shellcheck`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYjpuFwjXkJc"
      },
      "source": [
        "To avoid needing to think about `pre-commit`\n",
        "(was the command `pre-commit run` or `pre-commit check`?)\n",
        "while developing locally,\n",
        "we might put our linters into a shell script:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXlLFWmavLr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e34042-a5c0-4168-cb90-b8328ce1abb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/bin/bash\n",
            "set -uo pipefail\n",
            "set +e\n",
            "\n",
            "FAILURE=false\n",
            "\n",
            "# apply automatic formatting\n",
            "echo \"black\"\n",
            "pre-commit run black || FAILURE=true\n",
            "\n",
            "# check for python code style violations, see .flake8 for details\n",
            "echo \"flake8\"\n",
            "pre-commit run flake8 || FAILURE=true\n",
            "\n",
            "# check for shell scripting style violations and common bugs\n",
            "echo \"shellcheck\"\n",
            "pre-commit run shellcheck || FAILURE=true\n",
            "\n",
            "# check python types\n",
            "echo \"mypy\"\n",
            "pre-commit run mypy || FAILURE=true\n",
            "\n",
            "if [ \"$FAILURE\" = true ]; then\n",
            "  echo \"Linting failed\"\n",
            "  exit 1\n",
            "fi\n",
            "echo \"Linting passed\"\n",
            "exit 0\n"
          ]
        }
      ],
      "source": [
        "!cat tasks/lint.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPxHpRIB3nbw"
      },
      "source": [
        "These kinds of short and simple shell scripts are common in projects\n",
        "of intermediate size.\n",
        "\n",
        "They are useful for adding automation and reducing friction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMuPBpAi2qwl"
      },
      "source": [
        "But these scripts are code,\n",
        "and all code is susceptible to bugs and subject to concerns of style consistency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQRg3ZqXvLr4"
      },
      "source": [
        "We can't check these scripts with tools that lint Python code,\n",
        "so we include a shell script linting tool,\n",
        "[`shellcheck`](https://www.shellcheck.net/),\n",
        "in our `pre-commit`.\n",
        "\n",
        "More so than checking for correct style,\n",
        "this tool checks for common bugs or surprising behaviors of shells,\n",
        "which are unfortunately numerous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkfhE1srvLr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d9ca8a-149f-47f2-f3d9-ccebd0b2bea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shellcheck...............................................................\u001b[42mPassed\u001b[m\n"
          ]
        }
      ],
      "source": [
        "script_filename = \"tasks/lint.sh\"\n",
        "!pre-commit run shellcheck --files {script_filename}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXU9TRrwvLr4"
      },
      "source": [
        "That script has already been tested, so we don't see any errors.\n",
        "\n",
        "Try copying over a script you've written yourself or\n",
        "even from a popular repo that you like\n",
        "(by adding to the notebook directory or by making a cell\n",
        "with `%%writefile` at the top)\n",
        "and test it by changing the `script_filename`.\n",
        "\n",
        "You'd be surprised at the classes of subtle bugs possible in bash!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81MhAL-TvLr5"
      },
      "source": [
        "### Try \"unofficial bash strict mode\" for louder failures in scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSwhs_zUvLr5"
      },
      "source": [
        "Another way to reduce bugs is to use the suggested \"unofficial bash strict mode\" settings by\n",
        "[@redsymbol](https://twitter.com/redsymbol),\n",
        "which appear at the top of the script:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-j0vSxEvLr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a2508f-dfc1-4e90-f516-52fa78ebda07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/bin/bash\n",
            "set -uo pipefail\n",
            "set +e\n"
          ]
        }
      ],
      "source": [
        "!head -n 3 tasks/lint.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2iJU5jlvLr5"
      },
      "source": [
        "The core idea of strict mode is to fail more loudly.\n",
        "This is a desirable behavior of scripts,\n",
        "like the ones we're writing,\n",
        "even though it's an undesirable behavior for an interactive shell --\n",
        "it would be unpleasant to be logged out every time you hit an error.\n",
        "\n",
        "`set -u` means scripts fail if a variable's value is `u`nset,\n",
        "i.e. not defined.\n",
        "Otherwise bash is perfectly happy to allow you to reference undefined variables.\n",
        "The result is just an empty string, which can lead to maddeningly weird behavior.\n",
        "\n",
        "`set -o pipefail` means failures inside a pipe of commands (`|`) propagate,\n",
        "rather than using the exit code of the last command.\n",
        "Unix tools are perfectly happy to work on nonsense input,\n",
        "like sorting error messages, instead of the filenames you meant to send.\n",
        "\n",
        "You can read more about these choices\n",
        "[here](http://redsymbol.net/articles/unofficial-bash-strict-mode/),\n",
        "and considerations for working with other non-conforming scripts in \"strict mode\"\n",
        "and for handling resource teardown when scripts error out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1XqsrU_XWWS"
      },
      "source": [
        "# Testing ML Codebases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPNzeq3NYF2W"
      },
      "source": [
        "## Testing Python code with `pytests`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq5e_x6gc9Vu"
      },
      "source": [
        "\n",
        "ML codebases are Python first and foremost, so first let's get some Python tests going."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DC3GxYz6_R9"
      },
      "source": [
        "At a basic level,\n",
        "we can write functions that `assert`\n",
        "that our code behaves as expected in\n",
        "a given scenario and include it in the same module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Rvd-GNwv63W1"
      },
      "outputs": [],
      "source": [
        "from text_recognizer.lit_models.metrics import test_character_error_rate\n",
        "\n",
        "test_character_error_rate??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVB2TsQS5BTq"
      },
      "source": [
        "The standard tool for testing Python code is\n",
        "[`pytest`]((https://docs.pytest.org/en/7.1.x/)).\n",
        "\n",
        "We can use it as a command-line tool in a variety of ways,\n",
        "including to execute these kinds of tests.\n",
        "\n",
        "If passed a filename, `pytest` will look for\n",
        "any classes that start with `Test` or\n",
        "any functions that start with `test_` and run them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "u8sQguyJvLr6",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db92a91-bdb4-4614-c7cb-781469faec5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.1.1, pluggy-1.3.0\n",
            "rootdir: /content/fsdl-text-recognizer-2022-labs, configfile: pyproject.toml\n",
            "plugins: cov-3.0.0, typeguard-2.13.3, anyio-3.7.1\n",
            "collected 1 item                                                                                   \u001b[0m\n",
            "\n",
            "text_recognizer/lit_models/metrics.py \u001b[32m.\u001b[0m\u001b[32m                                                      [100%]\u001b[0m\n",
            "\n",
            "---------- coverage: platform linux, python 3.10.12-final-0 ----------\n",
            "Name                                             Stmts   Miss Branch BrPart  Cover\n",
            "----------------------------------------------------------------------------------\n",
            "text_recognizer/__init__.py                          0      0      0      0   100%\n",
            "text_recognizer/callbacks/__init__.py                4      4      0      0     0%\n",
            "text_recognizer/callbacks/imtotext.py               72     72     32      0     0%\n",
            "text_recognizer/callbacks/model.py                  62     62     18      0     0%\n",
            "text_recognizer/callbacks/optim.py                   5      5      2      0     0%\n",
            "text_recognizer/callbacks/util.py                    8      8      2      0     0%\n",
            "text_recognizer/data/__init__.py                     8      8      0      0     0%\n",
            "text_recognizer/data/base_data_module.py            66     66      6      0     0%\n",
            "text_recognizer/data/emnist.py                     105    105     32      0     0%\n",
            "text_recognizer/data/emnist_lines.py               141    141     40      0     0%\n",
            "text_recognizer/data/fake_images.py                 27     27      2      0     0%\n",
            "text_recognizer/data/iam.py                        115    115     50      0     0%\n",
            "text_recognizer/data/iam_lines.py                  107    107     42      0     0%\n",
            "text_recognizer/data/iam_paragraphs.py             110    110     38      0     0%\n",
            "text_recognizer/data/mnist.py                       23     23      4      0     0%\n",
            "text_recognizer/data/sentence_generator.py          52     52     20      0     0%\n",
            "text_recognizer/data/util.py                        38     38     14      0     0%\n",
            "text_recognizer/lit_models/__init__.py               2      0      0      0   100%\n",
            "text_recognizer/lit_models/base.py                  95     70     16      0    26%\n",
            "text_recognizer/lit_models/metrics.py               19      1      8      1    93%\n",
            "text_recognizer/lit_models/transformer.py           62     48     14      0    21%\n",
            "text_recognizer/lit_models/util.py                  15     11      2      0    24%\n",
            "text_recognizer/models/__init__.py                   5      5      0      0     0%\n",
            "text_recognizer/models/cnn.py                       55     55      4      0     0%\n",
            "text_recognizer/models/line_cnn.py                  68     68     12      0     0%\n",
            "text_recognizer/models/line_cnn_simple.py           42     42      6      0     0%\n",
            "text_recognizer/models/line_cnn_transformer.py      83     83      8      0     0%\n",
            "text_recognizer/models/mlp.py                       39     39      2      0     0%\n",
            "text_recognizer/models/resnet_transformer.py        96     96     14      0     0%\n",
            "text_recognizer/models/transformer_util.py          46     46      4      0     0%\n",
            "text_recognizer/util.py                             41     41     14      0     0%\n",
            "training/__init__.py                                 0      0      0      0   100%\n",
            "training/run_experiment.py                          88     88     20      0     0%\n",
            "training/util.py                                    15     15      0      0     0%\n",
            "----------------------------------------------------------------------------------\n",
            "TOTAL                                             1714   1651    426      1     4%\n",
            "\n",
            "\n",
            "\u001b[32m======================================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 11.01s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest text_recognizer/lit_models/metrics.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92tkBCllvLr6"
      },
      "source": [
        "After the results of the tests (pass or fail) are returned,\n",
        "you'll see a report of \"coverage\" from\n",
        "[`codecov`](https://about.codecov.io/).\n",
        "\n",
        "This coverage report tells us which files and how many lines in those files\n",
        "were at touched by the testing suite."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PllSUe0s5xvU"
      },
      "source": [
        "We do not actually need to provide the names of files with tests in them to `pytest`\n",
        "in order for it to run our tests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qOBHJnTZM9x"
      },
      "source": [
        "By default, `pytest` looks for any files named `test_*.py` or `*_test.py`.\n",
        "\n",
        "It's [good practice](https://docs.pytest.org/en/7.1.x/explanation/goodpractices.html#test-discovery)\n",
        "to separate these from the rest of your code\n",
        "in a folder or folders named `tests`,\n",
        "rather than scattering them around the repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "acjsYTNSvLr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165988be-85e0-40b9-ea08-fb42e7f99401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__pycache__  test_callback_utils.py  test_iam.py\n"
          ]
        }
      ],
      "source": [
        "!ls text_recognizer/tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZQQZUF0vLr6"
      },
      "source": [
        "Let's take a look at a specific example:\n",
        "the tests for some of our utilities around\n",
        "custom PyTorch Lightning `Callback`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oS0xKv1evLr6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9a9d1769-0bd0-4e0f-e4ea-3d5aaf2793f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tests for the text_recognizer.callbacks.util module.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from text_recognizer.tests import test_callback_utils\n",
        "\n",
        "\n",
        "test_callback_utils.__doc__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lko8msn-vLr7"
      },
      "source": [
        "Notice that we can easily import this as a module!\n",
        "\n",
        "That's another benefit of organizing tests into specialized files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A85FUNv75Fr"
      },
      "source": [
        "The particular utility we're testing\n",
        "here is designed to prevent crashes:\n",
        "it checks for a particular type of error and turns it into a warning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Jl4-DiVe76sw"
      },
      "outputs": [],
      "source": [
        "from text_recognizer.callbacks.util import check_and_warn\n",
        "\n",
        "check_and_warn??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6E0MhduvLr7"
      },
      "source": [
        "Error-handling code is a common cause of bugs,\n",
        "a fact discovered\n",
        "[again and again across forty years of error analysis](https://twitter.com/full_stack_dl/status/1561880960886505473?s=20&t=5OZBonILaUJE9J4ah2Qn0Q),\n",
        "so it's very important to test it well!\n",
        "\n",
        "We start with a very basic test,\n",
        "which does not touch anything\n",
        "outside of the Python standard library,\n",
        "even though this tool is intended to be used\n",
        "with more complex features of third-party libraries,\n",
        "like `wandb` and `tensorboard`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xx5koQmJvLr7"
      },
      "outputs": [],
      "source": [
        "test_callback_utils.test_check_and_warn_simple??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZe9-JVjvLr7"
      },
      "source": [
        "Here, we are just testing the core logic.\n",
        "This test won't catch many bugs,\n",
        "but when it does fail, something has gone seriously wrong.\n",
        "\n",
        "These kinds of tests are important for resolving a bug:\n",
        "we learn nearly as much from the tests that passed\n",
        "as we did from the tests that failed.\n",
        "If this test has failed, possibly along with others,\n",
        "we can rule out an issue in one of the large external codebases\n",
        "touched in the other tests, saving us lots of time in our troubleshooting.\n",
        "\n",
        "The reasoning for the test is explained in the docstrings,\n",
        "which are close to the code.\n",
        "\n",
        "Your test suite should be as welcoming\n",
        "as the rest of your codebase!\n",
        "The people reading it, for example yourself in six months,\n",
        "are likely upset and in need of some kindness.\n",
        "\n",
        "More practically, we want keep our time to resolve errors as short as possible,\n",
        "and five minutes to write a good docstring now\n",
        "can save five minutes during an outage, when minutes really matter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om9k-uXhvLr7"
      },
      "source": [
        "That basic test is a start, but it's not enough by itself.\n",
        "There's a specific error case that triggered the addition of this code.\n",
        "\n",
        "So we test that it's handled as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjbsb5FvvLr7"
      },
      "outputs": [],
      "source": [
        "test_callback_utils.test_check_and_warn_tblogger??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGAIZTUjvLr7"
      },
      "source": [
        "That test can fail if the libraries change around our code,\n",
        "i.e. if the `TensorBoardLogger` gets a `log_table` method.\n",
        "\n",
        "We want to be careful when making assumptions\n",
        "about other people's software,\n",
        "especially for fast-moving libraries like Lightning.\n",
        "If we test that those assumptions hold willy-nilly,\n",
        "we'll end up with tests that fail because of\n",
        "harmless changes in our dependencies.\n",
        "\n",
        "Tests that require a ton of maintenance and updating\n",
        "without leading to code improvements soak up\n",
        "more engineering time than they save\n",
        "and cause distrust in the testing suite.\n",
        "\n",
        "We include this test because `TensorBoardLogger` getting\n",
        "a `log_table` method will _also_ change the behavior of our code\n",
        "in a breaking way, and we want to catch that before it breaks\n",
        "a model training job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsy95KAvvLr7"
      },
      "source": [
        "Adding error handling can also accidentally kill the \"happy path\"\n",
        "by raising an error incorrectly.\n",
        "\n",
        "So we explicitly test the _absence of an error_,\n",
        "not just its presence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRlIOkjmvLr8"
      },
      "outputs": [],
      "source": [
        "test_callback_utils.test_check_and_warn_wandblogger??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osiqpLynvLr8"
      },
      "source": [
        "There are more tests we could build, e.g. manipulating classes and testing the behavior,\n",
        "testing more classes that might be targeted by `check_and_warn`, or\n",
        "asserting that warnings are raised to the command line.\n",
        "\n",
        "But these three basic tests are likely to catch most changes that would break our code here,\n",
        "and they're a lot easier to write than the others.\n",
        "\n",
        "If this utility starts to get more usage and become a critical path for lots of features, we can always add more!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm285JE5vLr8"
      },
      "source": [
        "## Interleaving testing and documentation with `doctests`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHWQvgA8vLr8"
      },
      "source": [
        "One function of tests is to build user/reader confidence in code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrhiJBXFvLr8"
      },
      "source": [
        "One function of documentation is to build user/reader knowledge in code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vu12LDhvLr8"
      },
      "source": [
        "These functions are related. Let's put them together:\n",
        "put code in a docstring and test that code.\n",
        "\n",
        "This feature is part of the\n",
        "Python standard library via the\n",
        "[`doctest` module](https://docs.python.org/3/library/doctest.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmfIOwXd-Qt7"
      },
      "source": [
        "Here's an example from our `torch` utilities.\n",
        "\n",
        "The `first_appearance` function can be used to\n",
        "e.g. quickly look for stop tokens,\n",
        "giving the length of each sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzURGcD9vLr8"
      },
      "outputs": [],
      "source": [
        "from text_recognizer.lit_models.util import first_appearance\n",
        "\n",
        "\n",
        "first_appearance??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VtYcJ1WvLr8"
      },
      "source": [
        "Notice that in the \"Examples\" section,\n",
        "there's a short block of code formatted as a\n",
        "Python interpreter session,\n",
        "complete with outputs.\n",
        "\n",
        "We can copy and paste that code and\n",
        "check that we get the right outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dj4lNOxJvLr9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "first_appearance(torch.tensor([[1, 2, 3], [2, 3, 3], [1, 1, 1], [3, 1, 1]]), 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9AWHFoIvLr9"
      },
      "source": [
        "We can run the test with `pytest` by passing a command line argument,\n",
        "`--doctest-modules`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JMaAxv5ovLr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df32f3ad-2154-4aeb-df08-9ec3bbb5eb0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.1.1, pluggy-1.3.0\n",
            "rootdir: /content/fsdl-text-recognizer-2022-labs, configfile: pyproject.toml\n",
            "plugins: cov-3.0.0, typeguard-2.13.3, anyio-3.7.1\n",
            "collected 2 items                                                                                  \u001b[0m\n",
            "\n",
            "text_recognizer/lit_models/util.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                        [100%]\u001b[0m\n",
            "\n",
            "---------- coverage: platform linux, python 3.10.12-final-0 ----------\n",
            "Name                                             Stmts   Miss Branch BrPart  Cover\n",
            "----------------------------------------------------------------------------------\n",
            "text_recognizer/__init__.py                          0      0      0      0   100%\n",
            "text_recognizer/callbacks/__init__.py                4      4      0      0     0%\n",
            "text_recognizer/callbacks/imtotext.py               72     72     32      0     0%\n",
            "text_recognizer/callbacks/model.py                  62     62     18      0     0%\n",
            "text_recognizer/callbacks/optim.py                   5      5      2      0     0%\n",
            "text_recognizer/callbacks/util.py                    8      8      2      0     0%\n",
            "text_recognizer/data/__init__.py                     8      8      0      0     0%\n",
            "text_recognizer/data/base_data_module.py            66     66      6      0     0%\n",
            "text_recognizer/data/emnist.py                     105    105     32      0     0%\n",
            "text_recognizer/data/emnist_lines.py               141    141     40      0     0%\n",
            "text_recognizer/data/fake_images.py                 27     27      2      0     0%\n",
            "text_recognizer/data/iam.py                        115    115     50      0     0%\n",
            "text_recognizer/data/iam_lines.py                  107    107     42      0     0%\n",
            "text_recognizer/data/iam_paragraphs.py             110    110     38      0     0%\n",
            "text_recognizer/data/mnist.py                       23     23      4      0     0%\n",
            "text_recognizer/data/sentence_generator.py          52     52     20      0     0%\n",
            "text_recognizer/data/util.py                        38     38     14      0     0%\n",
            "text_recognizer/lit_models/__init__.py               2      0      0      0   100%\n",
            "text_recognizer/lit_models/base.py                  95     70     16      0    26%\n",
            "text_recognizer/lit_models/metrics.py               19     11      8      1    41%\n",
            "text_recognizer/lit_models/transformer.py           62     48     14      0    21%\n",
            "text_recognizer/lit_models/util.py                  15      1      2      1    88%\n",
            "text_recognizer/models/__init__.py                   5      5      0      0     0%\n",
            "text_recognizer/models/cnn.py                       55     55      4      0     0%\n",
            "text_recognizer/models/line_cnn.py                  68     68     12      0     0%\n",
            "text_recognizer/models/line_cnn_simple.py           42     42      6      0     0%\n",
            "text_recognizer/models/line_cnn_transformer.py      83     83      8      0     0%\n",
            "text_recognizer/models/mlp.py                       39     39      2      0     0%\n",
            "text_recognizer/models/resnet_transformer.py        96     96     14      0     0%\n",
            "text_recognizer/models/transformer_util.py          46     46      4      0     0%\n",
            "text_recognizer/util.py                             41     41     14      0     0%\n",
            "training/__init__.py                                 0      0      0      0   100%\n",
            "training/run_experiment.py                          88     88     20      0     0%\n",
            "training/util.py                                    15     15      0      0     0%\n",
            "----------------------------------------------------------------------------------\n",
            "TOTAL                                             1714   1651    426      2     3%\n",
            "\n",
            "\n",
            "\u001b[32m======================================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 11.13s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest --doctest-modules text_recognizer/lit_models/util.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-2_aOUfvLr9"
      },
      "source": [
        "With the\n",
        "[right configuration](https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2022/blob/627dc9dabc9070cb14bfe5bfcb1d6131eb7dc7a8/pyproject.toml#L12-L17),\n",
        "running `doctest`s happens automatically\n",
        "when `pytest` is invoked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my_keokPvLr9"
      },
      "source": [
        "## Basic tests for data code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj3Bq_j2_A8o"
      },
      "source": [
        "ML code can be hard to test\n",
        "since it involes very heavy artifacts, like models and data,\n",
        "and very expensive jobs, like training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT5OmgrQvLr9"
      },
      "source": [
        "For testing our data-handling code in the FSDL codebase,\n",
        "we mostly just use `assert`s,\n",
        "which throw errors when behavior differs from expectation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Bdzn5g4TvLr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb64a4d0-99dd-49af-8174-8f6f1d4f2814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_recognizer/data/iam.py:    assert any(region is not None for region in line_regions), \"Line regions cannot be None\"\n",
            "text_recognizer/data/iam_lines.py:        self.input_dims = metadata.DIMS  # We assert that this is correct in setup()\n",
            "text_recognizer/data/iam_lines.py:        self.output_dims = metadata.OUTPUT_DIMS  # We assert that this is correct in setup()\n",
            "text_recognizer/data/iam_lines.py:            assert image_width <= metadata.IMAGE_WIDTH\n",
            "text_recognizer/data/iam_lines.py:            assert self.output_dims[0] >= max([len(_) for _ in labels_train]) + 2  # Add 2 for start/end tokens.\n",
            "text_recognizer/data/iam_lines.py:            assert self.output_dims[0] >= max([len(_) for _ in labels_val]) + 2  # Add 2 for start/end tokens.\n",
            "text_recognizer/data/iam_lines.py:            assert self.output_dims[0] >= max([len(_) for _ in labels_test]) + 2\n",
            "text_recognizer/data/iam_lines.py:    assert len(crops) == len(labels)\n",
            "text_recognizer/data/iam_lines.py:    assert len(crops) == len(labels)\n",
            "text_recognizer/data/iam_paragraphs.py:        self.input_dims = metadata.DIMS  # We assert that this is correct in setup()\n",
            "text_recognizer/data/iam_paragraphs.py:        self.output_dims = metadata.OUTPUT_DIMS  # We assert that this is correct in setup()\n",
            "text_recognizer/data/iam_paragraphs.py:    assert input_dims is not None and input_dims[1] >= max_image_shape[0] and input_dims[2] >= max_image_shape[1]\n",
            "text_recognizer/data/iam_paragraphs.py:    assert output_dims is not None and output_dims[0] >= properties[\"label_length\"][\"max\"] + 2\n",
            "text_recognizer/data/iam_paragraphs.py:    assert len(crops) == len(labels)\n",
            "text_recognizer/data/iam_paragraphs.py:    assert len(ordered_crops) == len(ordered_labels)\n"
          ]
        }
      ],
      "source": [
        "!grep \"assert\" -r text_recognizer/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aTlfu4_vLr-"
      },
      "source": [
        "This isn't great practice,\n",
        "especially as a codebase grows,\n",
        "because we can't easily know when these are executed\n",
        "or incorporate them into\n",
        "testing automation and coverage analysis tools."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaMTdmbZ_mkW"
      },
      "source": [
        "So it's preferable to collect up these assertions of simple data properties\n",
        "into tests that are run like our other tests.\n",
        "\n",
        "The test below checks whether any data is leaking\n",
        "between training, validation, and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qx7cxiDdvLr-"
      },
      "outputs": [],
      "source": [
        "from text_recognizer.tests.test_iam import test_iam_data_splits\n",
        "\n",
        "\n",
        "test_iam_data_splits??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16TJwhd1vLr-"
      },
      "source": [
        "Notice that we were able to load the test into the notebook\n",
        "because it is in a module,\n",
        "and so we can run it here as well:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mArITFkYvLr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9f3a7e-7918-4b3f-9978-46072ebf5132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading raw dataset from https://s3-us-west-2.amazonaws.com/fsdl-public-assets/iam/iamdb.zip to /content/fsdl-text-recognizer-2022-labs/data/downloaded/iam/iamdb.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "586MB [00:44, 13.9MB/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing SHA-256...\n",
            "Extracting IAM data\n"
          ]
        }
      ],
      "source": [
        "test_iam_data_splits()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4F2uaclvLr-"
      },
      "source": [
        "But we're checking something pretty simple here,\n",
        "so the new code in each test is just a single line.\n",
        "\n",
        "What if we wanted to test more complex properties,\n",
        "like comparing rows or calculating statistics?\n",
        "\n",
        "We'll end up writing more complex code that might itself have subtle bugs,\n",
        "requiring tests for our tests and suffering from\n",
        "\"tester's regress\".\n",
        "\n",
        "This is the phenomenon,\n",
        "named by analogy with\n",
        "[experimenter's regress](https://en.wikipedia.org/wiki/Experimenter%27s_regress)\n",
        "in sociology of science,\n",
        "where the validity of our tests is itself\n",
        "up for dispute only resolvable by testing the tests,\n",
        "but those tests are themselves possibly invalid."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUGT06gdvLr-"
      },
      "source": [
        "We cut this Gordian knot by using\n",
        "a library or framework that is well-tested.\n",
        "\n",
        "We recommend checking out\n",
        "[`great_expectations`](https://docs.greatexpectations.io/docs/)\n",
        "if you're looking for a high-quality data testing tool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ5vNsq3vLr-"
      },
      "source": [
        "Especially with data, some tests are particularly \"heavy\" --\n",
        "they take a long time,\n",
        "and we might want to run them\n",
        "on different machines\n",
        "and on a different schedule\n",
        "than our other tests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xephcb0LvLr-"
      },
      "source": [
        "For example, consider testing whether the download of a dataset succeeds and gives the right checksum.\n",
        "\n",
        "We can't just use a cached version of the data,\n",
        "since that won't actually execute the code!\n",
        "\n",
        "This test will take\n",
        "as long to run\n",
        "and consume as many resources as\n",
        "a full download of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSN4w2EqvLr-"
      },
      "source": [
        "`pytest` allows the separation of tests\n",
        "into suites with `mark`s,\n",
        "which \"tag\" tests with names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "V0rScrcXvLr_",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa74ab4-c6aa-4d85-c754-b0134e529418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@pytest.mark.slow: marks a test as slow (deselect with '-m \"not slow\"']\n",
            "\n",
            "@pytest.mark.data: marks a test as dependent on a data download (deselect with '-m \"not data\"')\n",
            "\n",
            "@pytest.mark.anyio: mark the (coroutine function) test to be run asynchronously via anyio.\n",
            "\n",
            "@pytest.mark.no_cover: disable coverage for this test.\n",
            "\n",
            "@pytest.mark.filterwarnings(warning): add a warning filter to the given test. see https://docs.pytest.org/en/stable/how-to/capture-warnings.html#pytest-mark-filterwarnings \n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pytest --markers | head -n 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr5Ca7B0vLr_"
      },
      "source": [
        "We can choose to run tests with a given mark\n",
        "or to skip tests with a given mark,\n",
        "among other basic logical operations around combining and filtering marks,\n",
        "with `-m`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xmw-Eb1ZvLr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b3498f-116a-40e2-b42c-c5ae3dcf5514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.1.1, pluggy-1.3.0\n",
            "rootdir: /content/fsdl-text-recognizer-2022-labs, configfile: pyproject.toml\n",
            "plugins: cov-3.0.0, typeguard-2.13.3, anyio-3.7.1\n",
            "collected 7 items                                                                                  \u001b[0m\n",
            "\n",
            "text_recognizer/lit_models/util.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                        [ 28%]\u001b[0m\n",
            "text_recognizer/tests/test_callback_utils.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                             [ 71%]\u001b[0m\n",
            "text_recognizer/tests/test_iam.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                         [100%]\u001b[0m\n",
            "\n",
            "---------- coverage: platform linux, python 3.10.12-final-0 ----------\n",
            "Name                                             Stmts   Miss Branch BrPart  Cover\n",
            "----------------------------------------------------------------------------------\n",
            "text_recognizer/__init__.py                          0      0      0      0   100%\n",
            "text_recognizer/callbacks/__init__.py                4      0      0      0   100%\n",
            "text_recognizer/callbacks/imtotext.py               72     48     32      0    27%\n",
            "text_recognizer/callbacks/model.py                  62     37     18      0    36%\n",
            "text_recognizer/callbacks/optim.py                   5      1      2      0    86%\n",
            "text_recognizer/callbacks/util.py                    8      0      2      0   100%\n",
            "text_recognizer/data/__init__.py                     8      0      0      0   100%\n",
            "text_recognizer/data/base_data_module.py            66     36      6      0    44%\n",
            "text_recognizer/data/emnist.py                     105     72     32      1    26%\n",
            "text_recognizer/data/emnist_lines.py               141    106     40      1    21%\n",
            "text_recognizer/data/fake_images.py                 27     15      2      0    48%\n",
            "text_recognizer/data/iam.py                        115     28     50      4    68%\n",
            "text_recognizer/data/iam_lines.py                  107     79     42      1    21%\n",
            "text_recognizer/data/iam_paragraphs.py             110     78     38      1    24%\n",
            "text_recognizer/data/mnist.py                       23     12      4      1    52%\n",
            "text_recognizer/data/sentence_generator.py          52     38     20      0    22%\n",
            "text_recognizer/data/util.py                        38     27     14      0    25%\n",
            "text_recognizer/lit_models/__init__.py               2      0      0      0   100%\n",
            "text_recognizer/lit_models/base.py                  95     70     16      0    26%\n",
            "text_recognizer/lit_models/metrics.py               19     11      8      1    41%\n",
            "text_recognizer/lit_models/transformer.py           62     48     14      0    21%\n",
            "text_recognizer/lit_models/util.py                  15      1      2      1    88%\n",
            "text_recognizer/metadata/emnist.py                  13      0      0      0   100%\n",
            "text_recognizer/metadata/emnist_lines.py             8      0      0      0   100%\n",
            "text_recognizer/metadata/iam.py                      7      0      0      0   100%\n",
            "text_recognizer/metadata/iam_lines.py               10      0      0      0   100%\n",
            "text_recognizer/metadata/iam_paragraphs.py          11      0      0      0   100%\n",
            "text_recognizer/metadata/mnist.py                    7      0      0      0   100%\n",
            "text_recognizer/metadata/shared.py                   3      0      0      0   100%\n",
            "text_recognizer/models/__init__.py                   5      0      0      0   100%\n",
            "text_recognizer/models/cnn.py                       55     39      4      0    34%\n",
            "text_recognizer/models/line_cnn.py                  68     47     12      0    31%\n",
            "text_recognizer/models/line_cnn_simple.py           42     28      6      0    33%\n",
            "text_recognizer/models/line_cnn_transformer.py      83     63      8      0    24%\n",
            "text_recognizer/models/mlp.py                       39     25      2      0    39%\n",
            "text_recognizer/models/resnet_transformer.py        96     75     14      0    21%\n",
            "text_recognizer/models/transformer_util.py          46     31      4      0    38%\n",
            "text_recognizer/stems/image.py                      17     10      6      0    48%\n",
            "text_recognizer/stems/line.py                       38     29     18      0    23%\n",
            "text_recognizer/stems/paragraph.py                  22     14     14      0    28%\n",
            "text_recognizer/tests/test_callback_utils.py        18      0      2      0   100%\n",
            "text_recognizer/tests/test_iam.py                   12      0      2      0   100%\n",
            "text_recognizer/util.py                             41     20     14      0    42%\n",
            "training/__init__.py                                 0      0      0      0   100%\n",
            "training/run_experiment.py                          88     72     20      1    16%\n",
            "training/util.py                                    15      9      0      0    40%\n",
            "----------------------------------------------------------------------------------\n",
            "TOTAL                                             1880   1169    468     12    35%\n",
            "\n",
            "\n",
            "\u001b[32m======================================== \u001b[32m\u001b[1m7 passed\u001b[0m\u001b[32m in 32.43s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!wandb login {key} # one test requires wandb authentication\n",
        "\n",
        "!pytest -m \"not data and not slow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LuERxOXX_UJ"
      },
      "source": [
        "## Testing training with memorization tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnWLN4lRvLsA"
      },
      "source": [
        "Training is the process by which we convert inert data into executable models,\n",
        "so it is dependent on both.\n",
        "\n",
        "We decouple checking whether the script has a critical bug\n",
        "from whether the data or model code is broken\n",
        "by testing on some basic \"fake data\",\n",
        "based on a utility from `torchvision`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "k4NIc3uWvLsA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "438abd62-6e6a-4184-be9a-48058f30e81d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Fake images dataset.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from text_recognizer.data import FakeImageData\n",
        "\n",
        "\n",
        "FakeImageData.__doc__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deN0swwlvLsA"
      },
      "source": [
        "We then test on the actual data with a smaller version of the real model.\n",
        "\n",
        "We use the Lightning `--fast_dev_run` feature,\n",
        "which sets the number of training, validation, and test batches to `1`.\n",
        "\n",
        "We use a smaller version so that this test can run in just a few minutes\n",
        "on a CPU without acceleration.\n",
        "\n",
        "That allows us to run our tests in environments without GPUs,\n",
        "which saves on costs for executing tests.\n",
        "\n",
        "Here's the script:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Z4J0_uD9vLsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f854765-dd33-4852-ebbe-719d45fd0098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/bin/bash\n",
            "set -uo pipefail\n",
            "set +e\n",
            "\n",
            "FAILURE=false\n",
            "\n",
            "echo \"running full loop test with CNN on fake data\"\n",
            "python training/run_experiment.py --data_class=FakeImageData --model_class=CNN --conv_dim=2 --fc_dim=2 --loss=cross_entropy --num_workers=4 --max_epochs=1 || FAILURE=true\n",
            "\n",
            "echo \"running fast_dev_run test of real model class on real data\"\n",
            "python training/run_experiment.py --data_class=IAMParagraphs --model_class=ResnetTransformer --loss=transformer \\\n",
            "  --tf_dim 4 --tf_fc_dim 2 --tf_layers 2 --tf_nhead 2 --batch_size 2 --lr 0.0001 \\\n",
            "  --fast_dev_run --num_sanity_val_steps 0 \\\n",
            "  --num_workers 1 || FAILURE=true\n",
            "\n",
            "if [ \"$FAILURE\" = true ]; then\n",
            "  echo \"Test for run_experiment.py failed\"\n",
            "  exit 1\n",
            "fi\n",
            "echo \"Tests for run_experiment.py passed\"\n",
            "exit 0\n"
          ]
        }
      ],
      "source": [
        "!cat training/tests/test_run_experiment.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Y-7u9zS1vLsA",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6603cba7-1de2-4b31-f7eb-4c082751c015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running full loop test with CNN on fake data\n",
            "2023-11-07 10:48:01.213388: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-07 10:48:01.213443: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-07 10:48:01.213483: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-07 10:48:02.320902: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Missing logger folder: training/logs/lightning_logs\n",
            "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "GPU available: True, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py:1812: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
            "  rank_zero_warn(\n",
            "\n",
            "  | Name           | Type      | Params\n",
            "---------------------------------------------\n",
            "0 | model          | CNN       | 874   \n",
            "1 | model.conv1    | ConvBlock | 20    \n",
            "2 | model.conv2    | ConvBlock | 38    \n",
            "3 | model.dropout  | Dropout   | 0     \n",
            "4 | model.max_pool | MaxPool2d | 0     \n",
            "5 | model.fc1      | Linear    | 786   \n",
            "6 | model.fc2      | Linear    | 30    \n",
            "7 | train_acc      | Accuracy  | 0     \n",
            "8 | val_acc        | Accuracy  | 0     \n",
            "9 | test_acc       | Accuracy  | 0     \n",
            "---------------------------------------------\n",
            "874       Trainable params\n",
            "0         Non-trainable params\n",
            "874       Total params\n",
            "0.003     Total estimated model params size (MB)\n",
            "Model State Dict Disk Size: 0.01 MB\n",
            "Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n",
            "Epoch 0:   0% 0/3 [00:00<?, ?it/s] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 3/3 [00:00<00:00,  7.58it/s, loss=2.36, v_num=0, validation/loss=2.370, validation/acc=0.0859]\n",
            "Epoch 0: 100% 3/3 [00:00<00:00,  7.38it/s, loss=2.36, v_num=0, validation/loss=2.370, validation/acc=0.0859]\n",
            "Best model saved at: /content/fsdl-text-recognizer-2022-labs/lab05/training/logs/lightning_logs/version_0/epoch=0000-validation.loss=2.373.ckpt\n",
            "Restoring states from the checkpoint path at /content/fsdl-text-recognizer-2022-labs/lab05/training/logs/lightning_logs/version_0/epoch=0000-validation.loss=2.373.ckpt\n",
            "Loaded model weights from checkpoint at /content/fsdl-text-recognizer-2022-labs/lab05/training/logs/lightning_logs/version_0/epoch=0000-validation.loss=2.373.ckpt\n",
            "Testing DataLoader 0: 100% 1/1 [00:00<00:00, 34.43it/s]\n",
            "\n",
            "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
            "\n",
            "\u001b[36m \u001b[0m\u001b[36m        test/acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.078125         \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    2.394085645675659    \u001b[0m\u001b[35m \u001b[0m\n",
            "\n",
            "running fast_dev_run test of real model class on real data\n",
            "2023-11-07 10:48:11.104077: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-07 10:48:11.104135: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-07 10:48:11.104168: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-07 10:48:12.214444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "GPU available: True, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py:1812: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
            "  rank_zero_warn(\n",
            "Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
            "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
            "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
            "`Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "IAMParagraphs.prepare_data: Cropping IAM paragraph regions and saving them along with labels...\n",
            "IAMParagraphs.setup(fit): Loading IAM paragraph regions and lines...\n",
            "\n",
            "   | Name                      | Type                    | Params\n",
            "-----------------------------------------------------------------------\n",
            "0  | model                     | ResnetTransformer       | 11.2 M\n",
            "1  | model.resnet              | Sequential              | 11.2 M\n",
            "2  | model.encoder_projection  | Conv2d                  | 2.1 K \n",
            "3  | model.enc_pos_encoder     | PositionalEncodingImage | 0     \n",
            "4  | model.embedding           | Embedding               | 336   \n",
            "5  | model.fc                  | Linear                  | 420   \n",
            "6  | model.dec_pos_encoder     | PositionalEncoding      | 0     \n",
            "7  | model.transformer_decoder | TransformerDecoder      | 412   \n",
            "8  | train_acc                 | Accuracy                | 0     \n",
            "9  | val_acc                   | Accuracy                | 0     \n",
            "10 | test_acc                  | Accuracy                | 0     \n",
            "11 | val_cer                   | CharacterErrorRate      | 0     \n",
            "12 | test_cer                  | CharacterErrorRate      | 0     \n",
            "13 | loss_fn                   | CrossEntropyLoss        | 0     \n",
            "-----------------------------------------------------------------------\n",
            "11.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "11.2 M    Total params\n",
            "44.719    Total estimated model params size (MB)\n",
            "Model State Dict Disk Size: 44.81 MB\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n",
            "Epoch 0:   0% 0/2 [00:00<?, ?it/s] /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.74s/it]\u001b[A\n",
            "Epoch 0: 100% 2/2 [00:04<00:00,  2.39s/it, loss=4.44, v_num=, validation/loss=4.440, validation/cer=0.987]\n",
            "Epoch 0: 100% 2/2 [00:04<00:00,  2.39s/it, loss=4.44, v_num=, validation/loss=4.440, validation/cer=0.987]\n",
            "IAMParagraphs.setup(test): Loading IAM paragraph regions and lines...\n",
            "Testing DataLoader 0: 100% 1/1 [00:01<00:00,  1.78s/it]\n",
            "\n",
            "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
            "\n",
            "\u001b[36m \u001b[0m\u001b[36m        test/cer         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m   0.9877883195877075    \u001b[0m\u001b[35m \u001b[0m\n",
            "\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    4.444047927856445    \u001b[0m\u001b[35m \u001b[0m\n",
            "\n",
            "Tests for run_experiment.py passed\n"
          ]
        }
      ],
      "source": [
        "! ./training/tests/test_run_experiment.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTzfo11KClV3"
      },
      "source": [
        "The above tests don't actaully check\n",
        "whether any learning occurs,\n",
        "they just check\n",
        "whether training runs mechanically,\n",
        "without any errors.\n",
        "\n",
        "We also need a\n",
        "[\"smoke test\"](https://en.wikipedia.org/wiki/Smoke_testing_(software))\n",
        "for learning.\n",
        "For that we recommending checking whether\n",
        "the model can learn the right\n",
        "outputs for a single batch --\n",
        "to \"memorize\" the outputs for\n",
        "a particular input.\n",
        "\n",
        "This memorization test won't\n",
        "catch every bug or issue in training,\n",
        "which is notoriously difficult,\n",
        "but it will flag\n",
        "some of the most serious issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DVSp3aAvLsA"
      },
      "source": [
        "The script below runs a memorization test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DFVVrxpvLsA"
      },
      "source": [
        "It takes up to two arguments:\n",
        "a `MAX`imum number of `EPOCHS` to run for and\n",
        "a `CRITERION` value of the loss to test against.\n",
        "\n",
        "The test passes if the loss is lower than the `CRITERION` value\n",
        "after the `MAX`imum number of `EPOCHS` has passed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEhJH0e5vLsB"
      },
      "source": [
        "The important line in this script is the one that invokes our training script,\n",
        "`training/run_experiment.py`.\n",
        "\n",
        "The arguments to `run_experiment` have been tuned for maximum possible speed:\n",
        "turning off regularization, shrinking the model,\n",
        "and skipping parts of Lightning that we don't want to test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "T-fFs1xEvLsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f2365f-6350-42e3-865e-14875926ed60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/bin/bash\n",
            "set -uo pipefail\n",
            "set +e\n",
            "\n",
            "# tests whether we can achieve a criterion loss\n",
            "#  on a single batch within a certain number of epochs\n",
            "\n",
            "FAILURE=false\n",
            "\n",
            "# constants and CLI args set by aiming for <5 min test on commodity GPU,\n",
            "#   including data download step\n",
            "MAX_EPOCHS=\"${1:-100}\"  # syntax for basic optional arguments in bash\n",
            "CRITERION=\"${2:-1.0}\"\n",
            "\n",
            "# train on GPU if it's available\n",
            "GPU=$(python -c 'import torch; print(int(torch.cuda.is_available()))')\n",
            "\n",
            "python ./training/run_experiment.py \\\n",
            "  --data_class=IAMParagraphs --model_class=ResnetTransformer --loss=transformer \\\n",
            "  --limit_test_batches 0.0 --overfit_batches 1 --num_sanity_val_steps 0 \\\n",
            "  --augment_data false --tf_dropout 0.0 \\\n",
            "  --gpus \"$GPU\" --precision 16 --batch_size 16 --lr 0.0001 \\\n",
            "  --log_every_n_steps 25 --max_epochs \"$MAX_EPOCHS\"  --num_workers 2 --wandb || FAILURE=true\n",
            "\n",
            "python -c \"import json; loss = json.load(open('training/logs/wandb/latest-run/files/wandb-summary.json'))['train/loss']; assert loss < $CRITERION\" || FAILURE=true\n",
            "\n",
            "if [ \"$FAILURE\" = true ]; then\n",
            "  echo \"Memorization test failed at loss criterion $CRITERION\"\n",
            "  exit 1\n",
            "fi\n",
            "echo \"Memorization test passed at loss criterion $CRITERION\"\n",
            "exit 0\n"
          ]
        }
      ],
      "source": [
        "!cat training/tests/test_memorize_iam.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-47tUA_YNGe"
      },
      "source": [
        "If you'd like to see what a memorization run looks like,\n",
        "flip the `running_memorization` flag to `True`\n",
        "and watch the results stream in to W&B.\n",
        "\n",
        "The cell should run in about ten minutes on a commodity GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GwTEsZwKvLsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e7e358-2775-472c-d061-b44d6bd677ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 10:50:51.592381: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-07 10:50:51.592442: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-07 10:50:51.592481: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-07 10:50:52.816574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaicmsaicm\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "2023-11-07 10:50:57.743957: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-07 10:50:57.744009: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-07 10:50:57.744045: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-07 10:50:58.788778: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mtraining/logs/wandb/run-20231107_105056-2yxnzkxt\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcerulean-firebrand-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/saicmsaicm/fsdl-text-recognizer-2022-labs-lab05_training\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/saicmsaicm/fsdl-text-recognizer-2022-labs-lab05_training/runs/2yxnzkxt\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "Using 16bit native Automatic Mixed Precision (AMP)\n",
            "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
            "IAMParagraphs.setup(fit): Loading IAM paragraph regions and lines...\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "   | Name                      | Type                    | Params\n",
            "-----------------------------------------------------------------------\n",
            "0  | model                     | ResnetTransformer       | 14.0 M\n",
            "1  | model.resnet              | Sequential              | 11.2 M\n",
            "2  | model.encoder_projection  | Conv2d                  | 131 K \n",
            "3  | model.enc_pos_encoder     | PositionalEncodingImage | 0     \n",
            "4  | model.embedding           | Embedding               | 21.5 K\n",
            "5  | model.fc                  | Linear                  | 21.6 K\n",
            "6  | model.dec_pos_encoder     | PositionalEncoding      | 0     \n",
            "7  | model.transformer_decoder | TransformerDecoder      | 2.6 M \n",
            "8  | train_acc                 | Accuracy                | 0     \n",
            "9  | val_acc                   | Accuracy                | 0     \n",
            "10 | test_acc                  | Accuracy                | 0     \n",
            "11 | val_cer                   | CharacterErrorRate      | 0     \n",
            "12 | test_cer                  | CharacterErrorRate      | 0     \n",
            "13 | loss_fn                   | CrossEntropyLoss        | 0     \n",
            "-----------------------------------------------------------------------\n",
            "14.0 M    Trainable params\n",
            "0         Non-trainable params\n",
            "14.0 M    Total params\n",
            "27.978    Total estimated model params size (MB)\n",
            "Model State Dict Disk Size: 56.07 MB\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:471: UserWarning: You requested to overfit but enabled training dataloader shuffling. We are turning off the training dataloader shuffling for you.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=25). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n",
            "Epoch 0:   0% 0/1 [00:00<?, ?it/s] /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Epoch 0: 100% 1/1 [00:10<00:00, 10.74s/it, loss=4.34, v_num=zkxt]/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:378: UserWarning: `ModelCheckpoint(monitor='validation/cer')` could not find the monitored key in the returned metrics: ['train/loss', 'epoch', 'step']. HINT: Did you call `log('validation/cer', value)` in the `LightningModule`?\n",
            "  warning_cache.warn(m)\n",
            "Epoch 99:   0% 0/1 [00:00<?, ?it/s, loss=1.35, v_num=zkxt]/usr/local/lib/python3.10/dist-packages/wandb/wandb_torch.py:175: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  check = torch.cuda.FloatTensor(1).fill_(0)\n",
            "Epoch 999: 100% 1/1 [00:03<00:00,  3.31s/it, loss=0.0175, v_num=zkxt]\n",
            "IAMParagraphs.setup(test): Loading IAM paragraph regions and lines...\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B sync reduced upload amount by 63.5%             \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   optimizer/lr-Adam \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        size/mb_disk \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        size/nparams \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/global_step \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch 999\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   optimizer/lr-Adam 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        size/mb_disk 56.06506\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        size/nparams 13988756\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss 0.0183\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/global_step 999\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mcerulean-firebrand-1\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/saicmsaicm/fsdl-text-recognizer-2022-labs-lab05_training/runs/2yxnzkxt\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 41 media file(s), 56 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mtraining/logs/wandb/run-20231107_105056-2yxnzkxt/logs\u001b[0m\n",
            "Memorization test passed at loss criterion 0.05\n",
            "CPU times: user 6.29 s, sys: 760 ms, total: 7.05 s\n",
            "Wall time: 13min 21s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "running_memorization = False\n",
        "\n",
        "if running_memorization:\n",
        "    max_epochs = 1000\n",
        "    loss_criterion = 0.05\n",
        "    !./training/tests/test_memorize_iam.sh {max_epochs} {loss_criterion}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPoFCoEcC8SV"
      },
      "source": [
        "# Troubleshooting model speed with the PyTorch Profiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpbN-Om2Drf-"
      },
      "source": [
        "Testing code is only half the story here:\n",
        "we also need to fix the issues that our tests flag.\n",
        "This is the process of troubleshooting.\n",
        "\n",
        "In this lab,\n",
        "we'll focus on troubleshooting model performance issues:\n",
        "what do to when your model runs too slowly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZzwELPXvLsD"
      },
      "source": [
        "Troubleshooting deep neural networks for speed is challenging.\n",
        "\n",
        "There are at least three different common approaches,\n",
        "each with an increasing level of skill required:\n",
        "\n",
        "1. Follow best practices advice from others\n",
        "([this @karpathy tweet](https://t.co/7CIDWfrI0J), summarizing\n",
        "[this NVIDIA talk](https://www.youtube.com/watch?v=9mS1fIYj1So&ab_channel=ArunMallya), is a popular place to start) and use existing implementations.\n",
        "2. Take code that runs slowly and use empirical observations to iteratively improve it.\n",
        "3. Truly understand distributed, accelerated tensor computations so you can write code correctly from scratch the first time.\n",
        "\n",
        "For the full stack deep learning engineer,\n",
        "the final level is typically out of reach,\n",
        "unless you're specializing in the model performance\n",
        "part of the stack in particular.\n",
        "\n",
        "So we recommend reaching the middle level,\n",
        "and this segment of the lab walks through the\n",
        "tools that make this easier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_yp87UrFZ8M"
      },
      "source": [
        "Because neural network training involves GPU acceleration,\n",
        "generic Python profiling tools like\n",
        "[`py-spy`](https://github.com/benfred/py-spy)\n",
        "won't work, and\n",
        "we'll need tools specialized for tracing and profiling DNN training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yspsYVFGEyZm"
      },
      "source": [
        "In general, these tools are for observing what happens while your code is executing:\n",
        "_tracing_ which operations were happening when and summarizing that into a _profile_ of the code.\n",
        "\n",
        "Because they help us observe the execution in detail,\n",
        "they will also help us understand just what is going on during\n",
        "a PyTorch training step in greater detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqXq2hKuvLsE"
      },
      "source": [
        "To support profiling and tracing,\n",
        "we've added a new argument to `training/run_experiment.py`, `--profile`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "z_GMMViWvLsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21174e8b-ddf1-4cb5-dae8-49d07a5e7b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 11:04:46.634432: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-07 11:04:46.634491: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-07 11:04:46.634530: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-07 11:04:47.702557: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "  --profile             If passed, uses the PyTorch Profiler to track computation, exported as a\n",
            "                        Chrome-style trace.\n"
          ]
        }
      ],
      "source": [
        "!python training/run_experiment.py --help | grep -A 1 -e \"^\\s*--profile\\s\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZldoksHPvLsE"
      },
      "source": [
        "As with experiment management, this relies mostly on features of PyTorch Lightning,\n",
        "which themselves wrap core utilities from libraries like PyTorch and TensorBoard,\n",
        "and we just add a few lines of customization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "F2iJ0_A6vLsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e817df-f1a4-420b-c543-eee4b22a0b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    if args.profile:\n",
            "        sched = torch.profiler.schedule(wait=0, warmup=3, active=4, repeat=0)\n",
            "        profiler = pl.profiler.PyTorchProfiler(export_to_chrome=True, schedule=sched, dirpath=experiment_dir)\n",
            "        profiler.STEP_FUNCTIONS = {\"training_step\"}  # only profile training\n",
            "    else:\n",
            "        profiler = pl.profiler.PassThroughProfiler()\n"
          ]
        }
      ],
      "source": [
        "!cat training/run_experiment.py | grep args.profile -A 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw3ppgndvLsE"
      },
      "source": [
        "For more on profiling with Lightning, see the\n",
        "[Lightning tutorial](https://pytorch-lightning.readthedocs.io/en/1.6.1/advanced/profiler.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCAmNW3QEtcD"
      },
      "source": [
        "The cell below runs an epoch of training with tracing and profiling turned on\n",
        "and then saves the results locally and to W&B."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "t4o3ylDgr46F",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "da27c343f03143c99d88a539357eee9c",
            "57c769f4b998451388cf24427ac738e2",
            "115a30ac7ce648979cf8d0a97e440e19",
            "21356d0885b94e0da896d02f0734940e",
            "0419723c2696437a80008d5017ad1c5a",
            "b0dcd93303c445b7841ad84ec9b05e54",
            "3b9cbfb3e49d4ff88d81bf39f6b0ff16",
            "a03df0c822714f728248d24dd8500985",
            "222a3a984caf4aa58070356b6bb09bea",
            "4a9fe9d8dcc94ddead96b176aa0fc38a",
            "bea09ff21ba045a78b5e1c12a7a67d90",
            "2093dc8d67f84f419ea0f1bfdcbc782c",
            "21b5e8e1624b42219472acbf7cb467d1",
            "f55180f4cc4e44359cb24edfeab13487",
            "e24a53dd492143789196fcdab71e95da",
            "6a5e2e99ca73448a81c6b8fc9cdf1275",
            "2889fa0e6cad4cd4aa29ec378942a495",
            "fe3c02947d784205b1090991145c50cf",
            "4e14c59b43864f899ffaabc45d4512a7"
          ]
        },
        "outputId": "bf05cf05-5bd6-499c-80d9-7bbe31d730d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_JOB_TYPE=profile\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaicmsaicm\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "wandb version 0.15.12 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.17"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>training/logs/wandb/run-20231107_110906-1iq1hx0r</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/saicmsaicm/fsdl-text-recognizer-2022-labs-lab05_training/runs/1iq1hx0r\" target=\"_blank\">breezy-dawn-2</a></strong> to <a href=\"https://wandb.ai/saicmsaicm/fsdl-text-recognizer-2022-labs-lab05_training\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True, used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IAMParagraphs.setup(fit): Loading IAM paragraph regions and lines...\n",
            "INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "   | Name                      | Type                    | Params\n",
            "-----------------------------------------------------------------------\n",
            "0  | model                     | ResnetTransformer       | 14.0 M\n",
            "1  | model.resnet              | Sequential              | 11.2 M\n",
            "2  | model.encoder_projection  | Conv2d                  | 131 K \n",
            "3  | model.enc_pos_encoder     | PositionalEncodingImage | 0     \n",
            "4  | model.embedding           | Embedding               | 21.5 K\n",
            "5  | model.fc                  | Linear                  | 21.6 K\n",
            "6  | model.dec_pos_encoder     | PositionalEncoding      | 0     \n",
            "7  | model.transformer_decoder | TransformerDecoder      | 2.6 M \n",
            "8  | train_acc                 | Accuracy                | 0     \n",
            "9  | val_acc                   | Accuracy                | 0     \n",
            "10 | test_acc                  | Accuracy                | 0     \n",
            "11 | val_cer                   | CharacterErrorRate      | 0     \n",
            "12 | test_cer                  | CharacterErrorRate      | 0     \n",
            "13 | loss_fn                   | CrossEntropyLoss        | 0     \n",
            "-----------------------------------------------------------------------\n",
            "14.0 M    Trainable params\n",
            "0         Non-trainable params\n",
            "14.0 M    Total params\n",
            "27.978    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model State Dict Disk Size: 56.07 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da27c343f03143c99d88a539357eee9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:378: UserWarning: `ModelCheckpoint(monitor='validation/cer')` could not find the monitored key in the returned metrics: ['train/loss', 'epoch', 'step']. HINT: Did you call `log('validation/cer', value)` in the `LightningModule`?\n",
            "  warning_cache.warn(m)\n",
            "INFO:pytorch_lightning.profiler.profiler:FIT Profiler Report\n",
            "Profile stats for: records\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          ProfilerStep*        13.08%     326.220ms        49.42%        1.233s     308.139ms       0.000us         0.00%      99.168ms      24.792ms             4  \n",
            "                        [pl][profile]run_training_batch         0.42%      10.504ms        38.44%     958.832ms     239.708ms       0.000us         0.00%     214.806ms      53.702ms             4  \n",
            "[pl][profile][LightningModule]TransformerLitModel.op...        22.71%     566.459ms        38.02%     948.179ms     237.045ms       0.000us         0.00%     214.806ms      53.702ms             4  \n",
            "[pl][profile][Strategy]SingleDeviceStrategy.backward...        18.17%     453.216ms        18.27%     455.540ms     113.885ms       0.000us         0.00%      16.000us       4.000us             4  \n",
            "[pl][profile][Strategy]SingleDeviceStrategy.training...         0.31%       7.643ms        15.30%     381.500ms      95.375ms       0.000us         0.00%     286.756ms      71.689ms             4  \n",
            "                                        cudaMemcpyAsync         9.81%     244.758ms         9.81%     244.758ms       1.912ms       0.000us         0.00%       0.000us       0.000us           128  \n",
            "                                             aten::item         0.40%       9.903ms         9.66%     240.910ms     218.216us       0.000us         0.00%      10.000us       0.009us          1104  \n",
            "                              aten::_local_scalar_dense         0.01%     224.000us         9.26%     231.008ms     209.246us      10.000us         0.00%      10.000us       0.009us          1104  \n",
            "                                            aten::copy_         2.86%      71.223ms         8.42%     209.880ms     103.287us      82.740ms        10.42%      83.425ms      41.056us          2032  \n",
            "[pl][module]torch.nn.modules.transformer.Transformer...         0.07%       1.801ms         7.64%     190.536ms      47.634ms       0.000us         0.00%     110.134ms      27.534ms             4  \n",
            "                                               aten::to         0.38%       9.483ms         5.45%     136.033ms      88.104us       0.000us         0.00%      39.202ms      25.390us          1544  \n",
            "                                         aten::_to_copy         0.39%       9.653ms         5.10%     127.219ms      88.840us       0.000us         0.00%      40.012ms      27.941us          1432  \n",
            "[pl][module]torch.nn.modules.container.Sequential: m...         0.17%       4.235ms         4.88%     121.654ms      30.413ms       0.000us         0.00%     170.187ms      42.547ms             4  \n",
            "                                       cudaLaunchKernel         4.37%     109.114ms         4.37%     109.114ms      25.026us       0.000us         0.00%       0.000us       0.000us          4360  \n",
            "                                           aten::conv2d         0.04%       1.042ms         3.76%      93.827ms     558.494us       0.000us         0.00%     198.529ms       1.182ms           168  \n",
            "                               Optimizer.step#Adam.step         1.53%      38.241ms         3.49%      86.996ms      21.749ms       0.000us         0.00%      17.184ms       4.296ms             4  \n",
            "                                            aten::clone         0.30%       7.596ms         3.39%      84.428ms     173.008us       0.000us         0.00%      26.606ms      54.520us           488  \n",
            "                                           aten::linear         0.12%       2.953ms         3.13%      78.175ms     336.961us       0.000us         0.00%      28.557ms     123.091us           232  \n",
            "                                            aten::empty         2.59%      64.708ms         2.59%      64.708ms      31.782us       0.000us         0.00%       0.000us       0.000us          2036  \n",
            "                                          aten::reshape         0.26%       6.452ms         2.56%      63.862ms      91.231us       0.000us         0.00%      19.795ms      28.279us           700  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 2.494s\n",
            "Self CUDA time total: 794.294ms\n",
            "\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IAMParagraphs.setup(test): Loading IAM paragraph regions and lines...\n",
            "INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='16.383 MB of 16.383 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2093dc8d67f84f419ea0f1bfdcbc782c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>optimizer/lr-Adam</td><td></td></tr><tr><td>size/mb_disk</td><td></td></tr><tr><td>size/nparams</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>optimizer/lr-Adam</td><td>0.001</td></tr><tr><td>size/mb_disk</td><td>56.06506</td></tr><tr><td>size/nparams</td><td>13988756</td></tr><tr><td>train/loss</td><td>3.18367</td></tr><tr><td>trainer/global_step</td><td>49</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">breezy-dawn-2</strong>: <a href=\"https://wandb.ai/saicmsaicm/fsdl-text-recognizer-2022-labs-lab05_training/runs/1iq1hx0r\" target=\"_blank\">https://wandb.ai/saicmsaicm/fsdl-text-recognizer-2022-labs-lab05_training/runs/1iq1hx0r</a><br/>Synced 5 W&B file(s), 2 media file(s), 18 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>training/logs/wandb/run-20231107_110906-1iq1hx0r/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "import torch\n",
        "import wandb\n",
        "\n",
        "from text_recognizer.data.base_data_module import DEFAULT_NUM_WORKERS\n",
        "\n",
        "\n",
        "# make it easier to separate these from training runs\n",
        "%env WANDB_JOB_TYPE=profile\n",
        "\n",
        "batch_size = 16\n",
        "num_workers = DEFAULT_NUM_WORKERS  # change this number later and see how the results change\n",
        "gpus = 1  # must be run with accelerator\n",
        "\n",
        "%run training/run_experiment.py --wandb --profile \\\n",
        "  --max_epochs=1 \\\n",
        "  --num_sanity_val_steps=0 --limit_val_batches=0 --limit_test_batches=0 \\\n",
        "  --model_class=ResnetTransformer --data_class=IAMParagraphs --loss=transformer \\\n",
        "  --batch_size={batch_size} --num_workers={num_workers} --precision=16 --gpus=1\n",
        "\n",
        "latest_expt = wandb.run\n",
        "\n",
        "try:  # add execution trace to logged and versioned binaries\n",
        "    folder = wandb.run.dir\n",
        "    trace_matcher = wandb.run.dir + \"/*.pt.trace.json\"\n",
        "    trace_file = glob.glob(trace_matcher)[0]\n",
        "    trace_at = wandb.Artifact(name=f\"trace-{wandb.run.id}\", type=\"trace\")\n",
        "    trace_at.add_file(trace_file, name=\"training_step.pt.trace.json\")\n",
        "    wandb.log_artifact(trace_at)\n",
        "except IndexError:\n",
        "    print(\"trace not found\")\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePTkS3EqO5tN"
      },
      "source": [
        "We get out a table of statistics in the terminal,\n",
        "courtesy of Lightning.\n",
        "\n",
        "Each row lists an operation\n",
        "and and provides information,\n",
        "described in the column headers,\n",
        "about the time spent on that operation\n",
        "across all the training steps we profiled.\n",
        "\n",
        "With practice, some useful information can be read out from this table,\n",
        "but it's better to start from both a less detailed view,\n",
        "in the TensorBoard dashboard,\n",
        "and a more detailed view,\n",
        "using the Chrome Trace viewer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzV62f3c7-Bi"
      },
      "source": [
        "## High-level statistics from the PyTorch Profiler in TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNPKXkYw8NWd"
      },
      "source": [
        "Let's look at the profiling info in a high-level TensorBoard dashboard, conveniently hosted for us on W&B."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "CbItwuT88eAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09e2fa4-e4a0-4963-ba6d-ce34b96a64e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://wandb.ai/saicmsaicm/fsdl-text-recognizer-2022-labs-lab05_training/runs/1iq1hx0r/tensorboard\n"
          ]
        }
      ],
      "source": [
        "your_tensorboard_url = latest_expt.url + \"/tensorboard\"\n",
        "\n",
        "print(your_tensorboard_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE_LooMYHFpF"
      },
      "source": [
        "If at any point you run into issues,\n",
        "like the description not matching what you observe,\n",
        "check out one of our example runs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "za2zybSwIo5C"
      },
      "outputs": [],
      "source": [
        "example_tensorboard_url = \"https://wandb.ai/cfrye59/fsdl-text-recognizer-2022-training/runs/67j1qxws/tensorboard?workspace=user-cfrye59\"\n",
        "print(example_tensorboard_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlrhl1n4HYU6"
      },
      "source": [
        "Once the TensorBoard session has loaded up,\n",
        "we are dropped into the Overview\n",
        "(see [this screenshot](https://pytorch.org/tutorials/_static/img/profiler_overview1.png)\n",
        "for an example).\n",
        "\n",
        "In the top center, we see the **GPU Summary** for our system.\n",
        "\n",
        "In addition to the name of our GPU,\n",
        "there are a few configuration details and top-level statistics.\n",
        "They are (tersely) documented\n",
        "[here](https://github.com/pytorch/kineto/blob/main/tb_plugin/docs/gpu_utilization.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmBhUDgDLhd1"
      },
      "source": [
        "- **[Compute Capability](https://developer.nvidia.com/cuda-gpus)**:\n",
        "this is effectively a coarse \"version number\" for your GPU hardware.\n",
        "It indexes which features are available,\n",
        "with more advanced features being available only at higher compute capabilities.\n",
        "It does not directly index the speed or memory of the GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voUgT6zuLyi0"
      },
      "source": [
        "- **GPU Utilization**: This metric represents the fraction of time an operation (a CUDA kernel) is running on the GPU. This is also reported by the `!nvidia-smi` command or in the sytem metrics tab in W&B. This metric will be our first target to increase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl-IndtXE4b4"
      },
      "source": [
        "- **[Tensor Cores](https://www.nvidia.com/en-us/data-center/tensor-cores/)**:\n",
        "for devices with compute capability of at least 7, you'll see information about how much your execution used DNN-specialized\n",
        "Tensor Cores.\n",
        "If you're running on an older GPU without Tensor Cores,\n",
        "you should consider upgrading.\n",
        "If you're running a more recent GPU but not seeing Tensor Core usage,\n",
        "you should switch to single precision floating point numbers,\n",
        "which Tensor Cores are specialized on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxcUf0bBNXy_"
      },
      "source": [
        "- **Est. SM Efficiency** and **Est. Occupancy** are high-level summaries of the utilization of GPU hardware\n",
        "at a lower level than just whether something is running at all,\n",
        "as in utilization.\n",
        "Unlike utilization, reaching 100% is not generally feasible\n",
        "and sometimes not desirable.\n",
        "Increasing these numbers requires expertise in\n",
        "CUDA programming, so we'll target utilization instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A88pQn4YMMKc"
      },
      "source": [
        "- **Execution Summary**: This table and pie chart indicates\n",
        "how much time within a profiled step\n",
        "was spent in each category.\n",
        "The value for \"kernel\" execution here\n",
        "is equal to the GPU utilization,\n",
        "and we want that number to be as close to 100%\n",
        "as possible.\n",
        "This summary helps us know which\n",
        "other operations are taking time,\n",
        "like memory being copied between CPU and GPU (`memcpy`)\n",
        "or `DataLoader`s executing on the CPU,\n",
        "so we can decide where the bottleneck is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qjW1RlTQRPv"
      },
      "source": [
        "At the very bottom, you'll find a\n",
        "**Performance Recommendation**\n",
        "tab that sometimes suggests specific methods for improving performance.\n",
        "\n",
        "If this tab makes suggestions, you should certainly take them!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWY5AhrcRQmJ"
      },
      "source": [
        "For more on using the profiler in TensorBoard,\n",
        "including some of the other, more detailed views\n",
        "available view the \"Views\" dropdown menu, see\n",
        "[this PyTorch tutorial](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html?highlight=profiler)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQwrPY_H77H8"
      },
      "source": [
        "## Going deeper with the Chrome Trace Viewer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhwo7fslvLsH"
      },
      "source": [
        "So far, we've seen summary-level information about our training steps\n",
        "in the table from Lightning and in the TensorBoard Overview.\n",
        "These give aggregate statistics about the computations that occurred,\n",
        "but understanding how to interpret those statistics\n",
        "and use them to speed up our networks\n",
        "requires understanding just what is\n",
        "happening in our training step.\n",
        "\n",
        "Fundamentally,\n",
        "all computations are processes that unfold in time.\n",
        "\n",
        "If we want to really understand our training step,\n",
        "we need to display it that way:\n",
        "what operations were occurring,\n",
        "on both the CPU and GPU,\n",
        "at each moment in time during the training step.\n",
        "\n",
        "This information on timing is collected in the trace.\n",
        "One of the best tools for viewing the trace over time\n",
        "is the [Chrome Trace Viewer](https://www.chromium.org/developers/how-tos/trace-event-profiling-tool/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUkZItxYc20A"
      },
      "source": [
        "Let's tour the trace we just logged\n",
        "with an aim to really understanding just\n",
        "what is happening when we call\n",
        "`training_step`\n",
        "and by extension `.forward`, `.backward`, and `optimizer.step`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w9F2UA7Qctg"
      },
      "source": [
        "The Chrome Trace Viewer is built into W&B,\n",
        "so we can view our traces in their interface.\n",
        "\n",
        "The cell below embeds the trace inside the notebook,\n",
        "but you may wish to open it separately,\n",
        "with the \"Open page\" button or by navigating to the URL,\n",
        "so that you can interact with it\n",
        "as you read the description below.\n",
        "Display directly on W&B is also a bit less temperamental\n",
        "than display on W&B inside a notebook.\n",
        "\n",
        "Furthermore, note that the Trace Viewer was originally built as part of the Chromium project,\n",
        "so it works best in browsers in that lineage -- Chrome, Edge, and Opera.\n",
        "It also can interact poorly with browser extensions (e.g. ad blockers),\n",
        "so you may need to deactivate them temporarily in order to see it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "OMUs4aby6Rfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "baf7b4aa-7a58-4795-edf4-57356fd463f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://wandb.ai/saicmsaicm/fsdl-text-recognizer-2022-labs-lab05_training/artifacts/trace/trace-1iq1hx0r/latest/files/training_step.pt.trace.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x797a53037820>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"1080.0\"\n",
              "            src=\"https://wandb.ai/saicmsaicm/fsdl-text-recognizer-2022-labs-lab05_training/artifacts/trace/trace-1iq1hx0r/latest/files/training_step.pt.trace.json\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "trace_files_url = latest_expt.url.split(\"/runs/\")[0] + f\"/artifacts/trace/trace-{latest_expt.id}/latest/files/\"\n",
        "trace_url = trace_files_url + \"training_step.pt.trace.json\"\n",
        "\n",
        "example_trace_url = \"https://wandb.ai/cfrye59/fsdl-text-recognizer-2022-training/artifacts/trace/trace-67j1qxws/latest/files/training_step.pt.trace.json\"\n",
        "\n",
        "print(trace_url)\n",
        "IFrame(src=trace_url, height=frame_height * 1.5, width=\"100%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNVpGeQtQjMG"
      },
      "source": [
        "> **Heads up!** We're about to do a tour of the\n",
        "> precise details of the tracing information logged\n",
        "> during the execution of the training code.\n",
        "> The only way to learn how to troubleshoot model performance\n",
        "> empirically is to look at the details,\n",
        "> but the details depend on the precise machine being used\n",
        "> -- GPU and CPU and RAM.\n",
        "> That means even within Colab,\n",
        "> these details change from session to session.\n",
        "> So if you don't observe a phenomenon or feature\n",
        "> described in the tour below, check out\n",
        "> [the example trace](https://wandb.ai/cfrye59/fsdl-text-recognizer-2022-training/artifacts/trace/trace-67j1qxws/latest/files/training_step.pt.trace.json)\n",
        "> on W&B while reading through the next section of the lab,\n",
        "> and return to your trace once you understand the trace viewer better at the end.\n",
        "> Also, these are very much bleeding-edge expert developer tools, so the UX and integrations\n",
        "> can sometimes be a bit janky."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXMcBhnCgdN_"
      },
      "source": [
        "This trace reveals, in nanosecond-level detail,\n",
        "what's going on inside of a `training_step`\n",
        "on both the GPU and the CPU.\n",
        "\n",
        "Time is on the horizontal axis.\n",
        "Colored bars represent method calls,\n",
        "and the methods called by a method are placed underneath it vertically,\n",
        "a visualization known as an\n",
        "[icicle chart](https://www.brendangregg.com/flamegraphs.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67BsNzDfVIeg"
      },
      "source": [
        "Let's orient ourselves with some gross features:\n",
        "the forwards pass,\n",
        "GPU kernel execution,\n",
        "the backwards pass,\n",
        "and the optimizer step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBEFgtRCKqrh"
      },
      "source": [
        "### The forwards pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nYhiWesVMjK"
      },
      "source": [
        "Type in `resnet` to the search bar in the top-right.\n",
        "\n",
        "This will highlight the first part of the forwards passes we traced, the encoding of the images with a ResNet.\n",
        "\n",
        "It should be in a vertical block of the trace that says `thread XYZ (python)` next to it.\n",
        "\n",
        "You can click the arrows next to that tile to partially collapse these blocks.\n",
        "\n",
        "Next, type in `transformerdecoder` to highlight the second part of our forwards pass.\n",
        "It should be at roughly the same height.\n",
        "\n",
        "Clear the search bar so that the trace is in color.\n",
        "Zoom in on the area of the forwards pass\n",
        "using the \"zoom\" tool in the floating toolbar,\n",
        "so you can see more detail.\n",
        "The zoom tool is indicated by a two-headed arrow\n",
        "pointing into and out of the screen.\n",
        "\n",
        "Switch to the \"drag\" tool,\n",
        "represented by a four-headed arrow.\n",
        "Click-and-hold to use this tool to focus\n",
        "on different parts of the timeline\n",
        "and click on the individual colored boxes\n",
        "to see details about a particular method call.\n",
        "\n",
        "As we go down in the icicle chart,\n",
        "we move from a very abstract level in Python (\"`resnet`\", \"`MultiheadAttention`\")\n",
        "to much more precise `cudnn` and `cuda` operations\n",
        "(\"`aten::cudnn_convolution`\", \"`aten::native_layer_norm`\").\n",
        "\n",
        "`aten` ([no relation to the Pharaoh](https://twitter.com/charles_irl/status/1422232585724432392?s=20&t=Jr4j5ZXhV20xGwUVD1rY0Q))\n",
        "is the tensor math library in PyTorch\n",
        "that links to specific backends like `cudnn`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq181ybIvLsH"
      },
      "source": [
        "### GPU kernel execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbkWp5aKvLsH"
      },
      "source": [
        "Towards the bottom, you should see a section labeled \"GPU\".\n",
        "The label appears on the far left.\n",
        "\n",
        "Within it, you'll see one or more \"`stream`s\".\n",
        "These are units of work on a GPU,\n",
        "akin loosely to threads on the CPU.\n",
        "\n",
        "When there are colored bars in this area,\n",
        "the GPU is doing work of some kind.\n",
        "The fraction of this bar that is filled in with color\n",
        "is the same as the \"GPU Utilization %\" we've seen previously.\n",
        "So the first thing to visually assess\n",
        "in a trace view of PyTorch code\n",
        "is what fraction of this area is filled with color.\n",
        "\n",
        "In CUDA, work is queued up to be\n",
        "placed into streams and completed, on the GPU,\n",
        "in a distributed and asynchronous manner.\n",
        "\n",
        "The selection of which work to do\n",
        "is happening on the CPU,\n",
        "and that's what we were looking at above.\n",
        "\n",
        "The CPU and the GPU have to work together to coordinate\n",
        "this work.\n",
        "\n",
        "Type `cuda` into the search bar and you'll see these coordination operations happening:\n",
        "`cudaLaunchKernel`, for example, is the CPU telling the GPU what to do.\n",
        "\n",
        "Running the same PyTorch model\n",
        "with the same high level operations like `Conv2d` in different versions of PyTorch,\n",
        "on different GPUs, and even on tensors of different sizes will result\n",
        "in different choices of concrete kernel operation,\n",
        "e.g. different matrix multiplication algorithms.\n",
        "\n",
        "Type `sync` into the search bar and you'll see places where either work on the GPU\n",
        "or work on the CPU needs to await synchronization,\n",
        "e.g. copying data from the CPU to the GPU\n",
        "or the CPU waiting to decide what to do next\n",
        "on the basis of the contents of a tensor.\n",
        "\n",
        "If you see a \"sync\" block above an area\n",
        "where the stream on the GPU is empty,\n",
        "you've got a performance bottleneck due to synchronization\n",
        "between the CPU and GPU.\n",
        "\n",
        "To resolve the bottleneck,\n",
        "head up the icicle chart until you reach the recognizable\n",
        "PyTorch modules and operations.\n",
        "Find where they are called in your PyTorch module.\n",
        "That's a good place to review your code to understand why the synchronization is happening\n",
        "and removing it if it's not necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeMPbu_jvLsI"
      },
      "source": [
        "### The backwards pass\n",
        "\n",
        "Type in `backward` into the search bar.\n",
        "\n",
        "This will highlight components of our backwards pass.\n",
        "\n",
        "If you read it from left to right,\n",
        "you'll see that it begins by calculating the loss\n",
        "(`NllLoss2DBackward` in the search bar if you can't find it)\n",
        "and ends by doing a `ConvolutionBackward`,\n",
        "the first layer of the ResNet.\n",
        "It is, indeed, backwards.\n",
        "\n",
        "Like the forwards pass,\n",
        "the backwards pass also involves the CPU\n",
        "telling the GPU which kernels to run.\n",
        "It's typically run in a separate\n",
        "thread from the forwards pass,\n",
        "so you'll see it separated out from the forwards pass\n",
        "in the trace viewer.\n",
        "\n",
        "Generally, there's no need to specifically optimize the backwards pass --\n",
        "removing bottlenecks in the forwards pass results in a fast backwards pass.\n",
        "\n",
        "One reason why is that these two passes are just\n",
        "\"transposes\" of one another,\n",
        "so they share a lot of properties,\n",
        "and bottlenecks in one become bottlenecks in the other.\n",
        "We can choose to optimize either one of the two.\n",
        "But the forwards pass is under our direct control,\n",
        "so it's easier for us to reason about.\n",
        "\n",
        "Another reason is that the forwards pass is more likely to have bottlenecks.\n",
        "The forwards pass is a dynamic process,\n",
        "with each line of Python adding more to the compute graph.\n",
        "Backwards passes, on the other hand, use a static compute graph,\n",
        "the one just defined by the forwards pass,\n",
        "so more optimizations are possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWiDw0vCvLsI"
      },
      "source": [
        "### The optimizer step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndfkzEdnvLsI"
      },
      "source": [
        "Type in `Adam.step` to the search bar to highlight the computations of the optimizer.\n",
        "\n",
        "As with the two passes,\n",
        "we are still using the CPU\n",
        "to launch kernels on the GPU.\n",
        "But now the CPU is looping,\n",
        "in Python, over the parameters\n",
        "and applying the ADAM updates rules to each.\n",
        "\n",
        "We now know enough to see that\n",
        "this is not great for our GPU utilization:\n",
        "there are many areas of gray\n",
        "in between the colored bars\n",
        "in the GPU stream in this area.\n",
        "\n",
        "In the time it takes CUDA to multiply\n",
        "thousands of numbers,\n",
        "Python has not yet finished cleaning up\n",
        "after its request for that multiplication.\n",
        "\n",
        "As of writing in August 2022,\n",
        "more efficient optimizers are not a stable part of PyTorch (v1.12), but\n",
        "[there is an unstable API](https://github.com/pytorch/pytorch/issues/68041)\n",
        "and stable implementations outside of PyTorch.\n",
        "The standard implementations are in\n",
        "[in NVIDIA's `apex.optimizers` library](https://nvidia.github.io/apex/optimizers.html),\n",
        "not to be confused with the\n",
        "[Apex Optimizers Project](https://www.apexoptimizers.com/),\n",
        "which is a collection of fitness-themed cheetah NFTs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX0jxeafvLsI"
      },
      "source": [
        "## Take-aways for PyTorch performance bottleneck troubleshooting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CugD-bK2vLsI"
      },
      "source": [
        "Our goal here was to learn some basic principles and tools for bottlenecking\n",
        "the most common issues and the lowest-hanging fruit in PyTorch code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwHwJkVMHYGA"
      },
      "source": [
        "\n",
        "Here's an overview in terms of a \"host\",\n",
        "generally the CPU,\n",
        "and a \"device\", here the GPU.\n",
        "\n",
        "- The slow-moving host operates at the level of an abstract compute graph (\"convolve these weights with this input\"), not actual numerical computations.\n",
        "- During execution, host's memory stores only metadata about tensors, like their types and shapes. This metadata needed to select the concrete operations, or CUDA kernels, for the device to run.\n",
        "  - Convolutions with very large filter sizes, for example, might use fast Fourier transform-based convolution algorithms, while the smaller filter sizes typical of contemporary CNNs are generally faster with Winograd-style convolution algorithms.\n",
        "- The much beefier device executes actual operations, but has no control over which operations are executed. Its memory\n",
        "stores information about the contents of tensors,\n",
        "not just their metadata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gntx28p9cBP5"
      },
      "source": [
        "Towards that goal, we viewed the trace to get an understanding of\n",
        "what's going on inside a PyTorch training step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKvZGPnkeXvq"
      },
      "source": [
        "Here's what we've means in terms of troubleshooting bottlenecks.\n",
        "\n",
        "We want Python to chew its way through looking up the right CUDA kernel and telling the GPU that's what it needs next\n",
        "before the previous kernel finishes.\n",
        "\n",
        "Ideally, the CPU is actually getting far _ahead_ of execution\n",
        "on the GPU.\n",
        "If the CPU makes it all the way through the backwards pass before the GPU is done,\n",
        "that's great!\n",
        "The GPU(s) are the expensive part,\n",
        "and it's easy to use multiprocessing so that\n",
        "the CPU has other things to do.\n",
        "\n",
        "This helps explain at least one common piece of advice:\n",
        "the larger our batches are,\n",
        "the more work the GPU has to do for the same work done by the CPU,\n",
        "and so the better our utilization will be."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMztpa-TccH4"
      },
      "source": [
        "We operationalize our desire to never be waiting on the CPU with a simple metric:\n",
        "**100% GPU utilization**, meaning a kernel is running at all times.\n",
        "\n",
        "This is the aggregate metric reported in the systems tab on W&B or in the output of `!nvidia-smi`.\n",
        "\n",
        "You should not buy faster GPUs until you have maxed this out! If you have 50% utilization, the fastest GPU in the world can't give you more than a 2x speedup, and it will more than 2x cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kYBygfScR6z"
      },
      "source": [
        "Here are some of the most common issues that lead to low GPU Utilization, and how to resolve them:\n",
        "1. **The CPU is too weak**.\n",
        "Because so much of the discussion around DNN performance is about GPUs,\n",
        "it's easy when specing out a machine to skimp on the CPUs, even though training can bottleneck on CPU operations.\n",
        "_Resolution_:\n",
        "Use nice CPUs, like\n",
        "[threadrippers](https://www.amd.com/en/products/ryzen-threadripper).\n",
        "2. **Too much Python during the `training_step`**.\n",
        "Python is very slow, so if you throw in a really slow Python operation, like dynamically creating classes or iterating over a bunch of bytes, especially from disk, during the training step, you can end up waiting on a `__init__`\n",
        "that takes longer than running an entire layer.\n",
        "_Resolution_:\n",
        "Look for low utilization areas of the trace\n",
        "and check what's happening on the CPU at that time\n",
        "and carefully review the Python code being executed.\n",
        "3. **Unnecessary Host/Device synchronization**.\n",
        "If one of your operations depends on the values in a tensor,\n",
        "like `if xs.mean() >= 0`,\n",
        "you'll induce a synchronization between\n",
        "the host and the device and possibly lead\n",
        "to an expensive and slow copy of data.\n",
        "_Resolution_:\n",
        "Replace these operations as much as possible\n",
        "with purely array-based calculations.\n",
        "4. **Bottlenecking on the DataLoader**.\n",
        "In addition to coordinating the work on the GPU,\n",
        "CPUs often perform heavy data operations,\n",
        "including communication over the network\n",
        "and writing to/reading from disk.\n",
        "These are generally done in parallel to the forwards\n",
        "and backwards passes,\n",
        "but if they don't finish before that happens,\n",
        "they will become the bottleneck.\n",
        "_Resolution_:\n",
        "Get better hardware for compute,\n",
        "memory, and network.\n",
        "For software solutions, the answer\n",
        "is a bit more complex and application-dependent.\n",
        "For generic tips, see\n",
        "[this classic post by Ross Wightman](https://discuss.pytorch.org/t/how-to-prefetch-data-when-processing-with-gpu/548/19)\n",
        "in the PyTorch forums.\n",
        "For techniques in computer vision, see\n",
        "[the FFCV library](https://github.com/libffcv/ffcv)\n",
        "and for techniques in NLP, see e.g.\n",
        "[Hugging Face datasets with Arrow](https://huggingface.co/docs/datasets/about_arrow)\n",
        "and [Hugging Face FastTokenizers](https://huggingface.co/course/chapter6/3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2WYS8bQvLsJ"
      },
      "source": [
        "### Further steps in making DNNs go brrrrrr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0wW2_lRKfY1"
      },
      "source": [
        "It's important to note that utilization\n",
        "is just an easily measured metric\n",
        "that can reveal common bottlenecks.\n",
        "Having high utilization does not automatically mean\n",
        "that your performance is fully optimized.\n",
        "\n",
        "For example,\n",
        "synchronization events between GPUs\n",
        "are counted as kernels,\n",
        "so a deadlock during distributed training\n",
        "can show up as 100% utilization,\n",
        "despite literally no useful work occurring.\n",
        "\n",
        "Just switching to\n",
        "double precision floats, `--precision=64`,\n",
        "will generally lead to much higher utilization.\n",
        "The GPU operations take longer\n",
        "for roughly the same amount of CPU effort,\n",
        "but the added precision brings no benefit.\n",
        "\n",
        "In particular, it doesn't make for models\n",
        "that perform better on our correctness metrics,\n",
        "like loss and accuracy.\n",
        "\n",
        "Another useful yardstick to add\n",
        "to utilization is examples per second,\n",
        "which incorporates how quickly the model is processing data examples\n",
        "and calculating gradients.\n",
        "\n",
        "But really,\n",
        "the gold star is _decrease in loss per second_.\n",
        "This metric connects model design choices\n",
        "and hyperparameters with purely engineering concerns,\n",
        "so it disrespects abstraction barriers\n",
        "and doesn't generally lead to actionable recommendations,\n",
        "but it is, in the end, the real goal:\n",
        "make the loss go down faster so we get better models sooner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFzPsplfdo_o"
      },
      "source": [
        "For PyTorch internals abstractly,\n",
        "see [Ed Yang's blog post](http://blog.ezyang.com/2019/05/pytorch-internals/).\n",
        "\n",
        "For more on performance considerations in PyTorch,\n",
        "see [Horace He's blog post](https://horace.io/brrr_intro.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFx-OhF837Bp"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq6-S6TC38AY"
      },
      "source": [
        "###  Compare `num_workers=0`  with `DEFAULT_NUM_WORKERS`.\n",
        "\n",
        "One of the most important features for making\n",
        "PyTorch run quickly is the\n",
        "`MultiprocessingDataLoader`,\n",
        "which executes batching of data in a separate process\n",
        "from the forwards and backwards passes.\n",
        "\n",
        "By default in PyTorch,\n",
        "this feature is actually turned off,\n",
        "via the `DataLoader` argument `num_workers`\n",
        "having a default value of `0`,\n",
        "but we set the `DEFAULT_NUM_WORKERS`\n",
        "to a value based on the number of CPUs\n",
        "available on the system running the code.\n",
        "\n",
        "Re-run the profiling cell,\n",
        "but set `num_workers` to `0`\n",
        "to turn off multiprocessing.\n",
        "\n",
        "Compare and contrast the two traces,\n",
        "both for total runtime\n",
        "(see the time axis at the top of the trace)\n",
        "and for utilization.\n",
        "\n",
        "If you're unable to run the profiles,\n",
        "see the results\n",
        "[here](https://wandb.ai/cfrye59/fsdl-text-recognizer-2022-training/artifacts/trace/trace-2eddoiz7/v0/files/training_step.pt.trace.json#f388e363f107e21852d5$trace-67j1qxws),\n",
        "which juxtaposes two traces,\n",
        "with in-process dataloading on the left and\n",
        "multiprocessing dataloading on the right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D39w0gXAiha"
      },
      "source": [
        "###  Resolve issues with a file by fixing flake8 lints, then write a test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2i_a5eVeIoA"
      },
      "source": [
        "The file below incorrectly implements and then incorrectly tests\n",
        "a simple PyTorch utility for adding five to every entry of a tensor\n",
        "and then calculating the sum.\n",
        "\n",
        "Even worse, it does it with horrible style!\n",
        "\n",
        "The cells below apply our linting checks\n",
        "(after automatically fixing the formatting)\n",
        "and run the test.\n",
        "\n",
        "Fix all of the lints,\n",
        "implement the function correctly,\n",
        "and then implement some basic tests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSon2fB5VVM_"
      },
      "source": [
        "- [`flake8`](https://flake8.pycqa.org/en/latest/user/error-codes.html) for core style\n",
        "- [`flake8-import-order`](https://github.com/PyCQA/flake8-import-order) for checking imports\n",
        "- [`flake8-docstrings`](https://github.com/pycqa/flake8-docstrings) for docstring style\n",
        "- [`darglint`](https://github.com/terrencepreilly/darglint) for docstring completeness\n",
        "- [`flake8-annotations`](https://github.com/sco1/flake8-annotations) for type annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYiRvU4HA84t"
      },
      "outputs": [],
      "source": [
        "%%writefile training/fixme.py\n",
        "import torch\n",
        "from training import run_experiment\n",
        "from numpy import *\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def add_five_and_sum(tensor):\n",
        "  # this function is not implemented right,\n",
        "  #    but it's supposed to add five to all tensor entries and sum them up\n",
        "  return 1\n",
        "\n",
        "def test_add_five_and_sum():\n",
        "    # and this test isn't right either! plus this isn't exactly a docstring\n",
        "    all_zeros, all_ones = torch.zeros((2, 3)), torch.ones((1, 4, 72))\n",
        "    all_fives = 5 * all_ones\n",
        "    assert False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXJpmvuzT1w0"
      },
      "outputs": [],
      "source": [
        "!pre-commit run black --files training/fixme.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRO-oJfdUrcQ"
      },
      "outputs": [],
      "source": [
        "!cat training/fixme.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM8NHxVbSEQD"
      },
      "outputs": [],
      "source": [
        "!pre-commit run --files training/fixme.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kj0VMBSndtkc"
      },
      "outputs": [],
      "source": [
        "!pytest training/fixme.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da27c343f03143c99d88a539357eee9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57c769f4b998451388cf24427ac738e2",
              "IPY_MODEL_115a30ac7ce648979cf8d0a97e440e19",
              "IPY_MODEL_21356d0885b94e0da896d02f0734940e"
            ],
            "layout": "IPY_MODEL_0419723c2696437a80008d5017ad1c5a"
          }
        },
        "57c769f4b998451388cf24427ac738e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0dcd93303c445b7841ad84ec9b05e54",
            "placeholder": "",
            "style": "IPY_MODEL_3b9cbfb3e49d4ff88d81bf39f6b0ff16",
            "value": "Epoch 0: 100%"
          }
        },
        "115a30ac7ce648979cf8d0a97e440e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a03df0c822714f728248d24dd8500985",
            "max": 68,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_222a3a984caf4aa58070356b6bb09bea",
            "value": 68
          }
        },
        "21356d0885b94e0da896d02f0734940e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a9fe9d8dcc94ddead96b176aa0fc38a",
            "placeholder": "",
            "style": "IPY_MODEL_bea09ff21ba045a78b5e1c12a7a67d90",
            "value": " 68/68 [00:48&lt;00:00,  1.41it/s, loss=3.21, v_num=hx0r]"
          }
        },
        "0419723c2696437a80008d5017ad1c5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "b0dcd93303c445b7841ad84ec9b05e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b9cbfb3e49d4ff88d81bf39f6b0ff16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a03df0c822714f728248d24dd8500985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "222a3a984caf4aa58070356b6bb09bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a9fe9d8dcc94ddead96b176aa0fc38a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bea09ff21ba045a78b5e1c12a7a67d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2093dc8d67f84f419ea0f1bfdcbc782c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21b5e8e1624b42219472acbf7cb467d1",
              "IPY_MODEL_f55180f4cc4e44359cb24edfeab13487"
            ],
            "layout": "IPY_MODEL_e24a53dd492143789196fcdab71e95da"
          }
        },
        "21b5e8e1624b42219472acbf7cb467d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a5e2e99ca73448a81c6b8fc9cdf1275",
            "placeholder": "",
            "style": "IPY_MODEL_2889fa0e6cad4cd4aa29ec378942a495",
            "value": "30.679 MB of 30.679 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "f55180f4cc4e44359cb24edfeab13487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe3c02947d784205b1090991145c50cf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e14c59b43864f899ffaabc45d4512a7",
            "value": 1
          }
        },
        "e24a53dd492143789196fcdab71e95da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a5e2e99ca73448a81c6b8fc9cdf1275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2889fa0e6cad4cd4aa29ec378942a495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe3c02947d784205b1090991145c50cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e14c59b43864f899ffaabc45d4512a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}